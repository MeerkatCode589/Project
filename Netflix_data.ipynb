{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeerkatCode589/Project/blob/main/Netflix_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL0GQgJHmLKG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file with the appropriate encoding\n",
        "file_path = '/content/netflix-tweets.csv'\n",
        "\n",
        "# Perform operations on the DataFrame\n",
        "# ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-9FGKRUtACM",
        "outputId": "00c552d8-1296-47da-9ffb-e633d0f6aeb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.10/dist-packages (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweet-preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR0FvD7eYflR",
        "outputId": "2dcf937e-fe2e-4a47-941a-7b2e6ac0eb5e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-81abfd63bac3>:1: DtypeWarning: Columns (6,7,54,55,56,57) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  netflix_df = pd.read_csv(file_path)\n"
          ]
        }
      ],
      "source": [
        "netflix_df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9QuoPYP7GWs"
      },
      "outputs": [],
      "source": [
        "num_columns = netflix_df.shape[1]\n",
        "print(f\"The number of columns in the dataset is: {num_columns}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "ddUuaKm33b8n",
        "outputId": "a4d9ff6d-a5de-4808-d149-81e986a7acc3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0bb9c74c-aab6-4d16-bbf3-ce3f89e4eafd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>banner_image</th>\n",
              "      <th>fullname</th>\n",
              "      <th>images/0</th>\n",
              "      <th>images/1</th>\n",
              "      <th>images/2</th>\n",
              "      <th>images/3</th>\n",
              "      <th>images/4</th>\n",
              "      <th>images/5</th>\n",
              "      <th>in_reply_to/0</th>\n",
              "      <th>in_reply_to/1</th>\n",
              "      <th>...</th>\n",
              "      <th>replies</th>\n",
              "      <th>retweets</th>\n",
              "      <th>text</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>total_likes</th>\n",
              "      <th>total_tweets</th>\n",
              "      <th>tweet_avatar</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>url</th>\n",
              "      <th>username</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>alan</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>I should say I'm no fan of streamers lying abo...</td>\n",
              "      <td>2023-06-30 06:15:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/165116431...</td>\n",
              "      <td>1674662809404166145</td>\n",
              "      <td>https://twitter.com/alan_muso/status/167466280...</td>\n",
              "      <td>@alan_muso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Atlantic Council</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>@netflix‚Äôs selection of @Adele_JJames as Queen...</td>\n",
              "      <td>2023-06-29 17:35:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/150454332...</td>\n",
              "      <td>1674471544804737024</td>\n",
              "      <td>https://twitter.com/AtlanticCouncil/status/167...</td>\n",
              "      <td>@AtlanticCouncil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Mr.2real4dabullshit</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Now why @netflix put out a movie with @tomhank...</td>\n",
              "      <td>2023-06-30 00:14:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/161506822...</td>\n",
              "      <td>1674572028744204288</td>\n",
              "      <td>https://twitter.com/realasitget314/status/1674...</td>\n",
              "      <td>@realasitget314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>The Atlantic Council Middle East Initiatives</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A recent trailer of the @Netflix series ‚ÄòQueen...</td>\n",
              "      <td>2023-06-29 17:05:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/713846775...</td>\n",
              "      <td>1674464004578717709</td>\n",
              "      <td>https://twitter.com/ACMideast/status/167446400...</td>\n",
              "      <td>@ACMideast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Peter Torres</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@netflix @jadapsmith \\nAn old man told me Cleo...</td>\n",
              "      <td>2023-06-28 20:52:00+00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/930134366...</td>\n",
              "      <td>1674158873891184643</td>\n",
              "      <td>https://twitter.com/PeterTorres14/status/16741...</td>\n",
              "      <td>@PeterTorres14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 74 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bb9c74c-aab6-4d16-bbf3-ce3f89e4eafd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-5b9cca36-4818-4603-ac3d-da8a28b1c1f8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b9cca36-4818-4603-ac3d-da8a28b1c1f8')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-5b9cca36-4818-4603-ac3d-da8a28b1c1f8 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bb9c74c-aab6-4d16-bbf3-ce3f89e4eafd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bb9c74c-aab6-4d16-bbf3-ce3f89e4eafd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   banner_image                                      fullname images/0  \\\n",
              "0           NaN                                          alan      NaN   \n",
              "1           NaN                              Atlantic Council      NaN   \n",
              "2           NaN                           Mr.2real4dabullshit      NaN   \n",
              "3           NaN  The Atlantic Council Middle East Initiatives      NaN   \n",
              "4           NaN                                  Peter Torres      NaN   \n",
              "\n",
              "  images/1 images/2 images/3 images/4 images/5 in_reply_to/0 in_reply_to/1  \\\n",
              "0      NaN      NaN      NaN      NaN      NaN           NaN           NaN   \n",
              "1      NaN      NaN      NaN      NaN      NaN           NaN           NaN   \n",
              "2      NaN      NaN      NaN      NaN      NaN           NaN           NaN   \n",
              "3      NaN      NaN      NaN      NaN      NaN           NaN           NaN   \n",
              "4      NaN      NaN      NaN      NaN      NaN           NaN           NaN   \n",
              "\n",
              "   ... replies retweets                                               text  \\\n",
              "0  ...       1        0  I should say I'm no fan of streamers lying abo...   \n",
              "1  ...       1        5  @netflix‚Äôs selection of @Adele_JJames as Queen...   \n",
              "2  ...       0        0  Now why @netflix put out a movie with @tomhank...   \n",
              "3  ...       1        0  A recent trailer of the @Netflix series ‚ÄòQueen...   \n",
              "4  ...       0        0  @netflix @jadapsmith \\nAn old man told me Cleo...   \n",
              "\n",
              "                   timestamp total_likes total_tweets  \\\n",
              "0  2023-06-30 06:15:00+00:00         NaN          NaN   \n",
              "1  2023-06-29 17:35:00+00:00         NaN          NaN   \n",
              "2  2023-06-30 00:14:00+00:00         NaN          NaN   \n",
              "3  2023-06-29 17:05:00+00:00         NaN          NaN   \n",
              "4  2023-06-28 20:52:00+00:00         NaN          NaN   \n",
              "\n",
              "                                        tweet_avatar             tweet_id  \\\n",
              "0  https://pbs.twimg.com/profile_images/165116431...  1674662809404166145   \n",
              "1  https://pbs.twimg.com/profile_images/150454332...  1674471544804737024   \n",
              "2  https://pbs.twimg.com/profile_images/161506822...  1674572028744204288   \n",
              "3  https://pbs.twimg.com/profile_images/713846775...  1674464004578717709   \n",
              "4  https://pbs.twimg.com/profile_images/930134366...  1674158873891184643   \n",
              "\n",
              "                                                 url          username  \n",
              "0  https://twitter.com/alan_muso/status/167466280...        @alan_muso  \n",
              "1  https://twitter.com/AtlanticCouncil/status/167...  @AtlanticCouncil  \n",
              "2  https://twitter.com/realasitget314/status/1674...   @realasitget314  \n",
              "3  https://twitter.com/ACMideast/status/167446400...        @ACMideast  \n",
              "4  https://twitter.com/PeterTorres14/status/16741...    @PeterTorres14  \n",
              "\n",
              "[5 rows x 74 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "netflix_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUQ7TlFTzrVb"
      },
      "source": [
        "It's easy to preview the first few rows of a `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUW63Cfd40Bt",
        "outputId": "0c565f9f-e11d-477f-b9de-c2e4c0f39764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['banner_image', 'fullname', 'images/0', 'images/1', 'images/2', 'images/3', 'images/4', 'images/5', 'in_reply_to/0', 'in_reply_to/1', 'in_reply_to/2', 'in_reply_to/3', 'in_reply_to/4', 'in_reply_to/5', 'in_reply_to/6', 'in_reply_to/7', 'in_reply_to/8', 'in_reply_to/9', 'in_reply_to/10', 'in_reply_to/11', 'in_reply_to/12', 'in_reply_to/13', 'in_reply_to/14', 'in_reply_to/15', 'in_reply_to/16', 'in_reply_to/17', 'in_reply_to/18', 'in_reply_to/19', 'in_reply_to/20', 'in_reply_to/21', 'in_reply_to/22', 'in_reply_to/23', 'in_reply_to/24', 'in_reply_to/25', 'in_reply_to/26', 'in_reply_to/27', 'in_reply_to/28', 'in_reply_to/29', 'in_reply_to/30', 'in_reply_to/31', 'in_reply_to/32', 'in_reply_to/33', 'in_reply_to/34', 'in_reply_to/35', 'in_reply_to/36', 'in_reply_to/37', 'in_reply_to/38', 'in_reply_to/39', 'in_reply_to/40', 'in_reply_to/41', 'in_reply_to/42', 'in_reply_to/43', 'in_reply_to/44', 'in_reply_to/45', 'in_reply_to/46', 'in_reply_to/47', 'in_reply_to/48', 'in_reply_to/49', 'language', 'likes', 'num_followers', 'num_following', 'query', 'quotes', 'replies', 'retweets', 'text', 'timestamp', 'total_likes', 'total_tweets', 'tweet_avatar', 'tweet_id', 'url', 'username']\n"
          ]
        }
      ],
      "source": [
        "print(netflix_df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Vj1uiT9zrVb"
      },
      "outputs": [],
      "source": [
        "netflix_df = netflix_df[['username','timestamp',\n",
        "                       'text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybn6Nazb8GT4",
        "outputId": "3e91dc14-dadc-4577-a034-16fdd0bae617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of rows in the dataset is: 22214\n"
          ]
        }
      ],
      "source": [
        "num_rows = netflix_df.shape[0]\n",
        "print(f\"The number of rows in the dataset is: {num_rows}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUHCRVr68NwJ"
      },
      "outputs": [],
      "source": [
        "netflix_df.drop_duplicates(inplace=True, subset=\"text\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zao8GM8l8aGF",
        "outputId": "e4a35cb2-86fd-4f0c-b13f-bbbf44ccb8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of rows in the dataset is: 20945\n"
          ]
        }
      ],
      "source": [
        "num_rows = netflix_df.shape[0]\n",
        "print(f\"The number of rows in the dataset is: {num_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL_UsYkv8iFt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import gensim\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "punctuation = '!‚Äù$%&\\‚Äô()*+,-./:;<=>?[\\\\]^_`{|}~‚Ä¢@'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoNHfh6m9Dyd"
      },
      "outputs": [],
      "source": [
        "def remove_links(text):\n",
        "    \"\"\"Takes a string and removes web links from it\"\"\"\n",
        "    text = re.sub(r'http\\S+', '', text)   # remove http links\n",
        "    text = re.sub(r'bit.ly/\\S+', '', text)  # remove bitly links\n",
        "    text = text.strip('[link]')   # remove [links]\n",
        "    text = re.sub(r'pic.twitter\\S+','', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yST12CUy9YNw"
      },
      "outputs": [],
      "source": [
        "def remove_users(text):\n",
        "    \"\"\"Takes a string and removes retweet and @user information\"\"\"\n",
        "    text = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', text)  # remove re-tweet\n",
        "    text = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', text)  # remove tweeted at\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO4WAF2N9h90"
      },
      "outputs": [],
      "source": [
        "def remove_hashtags(text):\n",
        "    \"\"\"Takes a string and removes any hash tags\"\"\"\n",
        "    text = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', text)  # remove hash tags\n",
        "    return text\n",
        "\n",
        "def remove_av(text):\n",
        "    \"\"\"Takes a string and removes AUDIO/VIDEO tags or labels\"\"\"\n",
        "    text = re.sub('VIDEO:', '', text)  # remove 'VIDEO:' from start of tweet\n",
        "    text = re.sub('AUDIO:', '', text)  # remove 'AUDIO:' from start of tweet\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKdlT40h9x0T"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    \"\"\"Returns tokenized representation of words in lemma form excluding stopwords\"\"\"\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS \\\n",
        "                and len(token) > 2:  # drops words with less than 3 characters\n",
        "            result.append(lemmatize(token))\n",
        "    return result\n",
        "\n",
        "def lemmatize(token):\n",
        "    \"\"\"Returns lemmatization of a token\"\"\"\n",
        "    return WordNetLemmatizer().lemmatize(token, pos='v')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADWGtjSy998f"
      },
      "outputs": [],
      "source": [
        "def preprocess_tweet(text):\n",
        "    \"\"\"Main master function to clean text, stripping noisy characters, and tokenizing use lemmatization\"\"\"\n",
        "    text = remove_users(text)\n",
        "    text = remove_links(text)\n",
        "    text = remove_hashtags(text)\n",
        "    text = remove_av(text)\n",
        "    text = text.lower()  # lower case\n",
        "    text = re.sub('[' + punctuation + ']+', ' ', text)  # strip punctuation\n",
        "    text = re.sub('\\s+', ' ', text)  # remove double spacing\n",
        "    text = re.sub('([0-9]+)', '', text)  # remove numbers\n",
        "    text_token_list = tokenize(text)  # apply lemmatization and tokenization\n",
        "    text = ' '.join(text_token_list)\n",
        "    return text\n",
        "\n",
        "def basic_clean(text):\n",
        "    \"\"\"Main master function to clean tweets only without tokenization or removal of stopwords\"\"\"\n",
        "    text = remove_users(text)\n",
        "    text = remove_links(text)\n",
        "    text = remove_hashtags(text)\n",
        "    text = remove_av(text)\n",
        "    text = text.lower()  # lower case\n",
        "    text = re.sub('[' + punctuation + ']+', ' ', text)  # strip punctuation\n",
        "    text = re.sub('\\s+', ' ', text)  # remove double spacing\n",
        "    text = re.sub('([0-9]+)', '', text)  # remove numbers\n",
        "    text = re.sub('üìù ‚Ä¶', '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnMremmR-8nz"
      },
      "outputs": [],
      "source": [
        "def tokenize_tweets(netflix_df):\n",
        "    \"\"\"Main function to read in and return cleaned and preprocessed dataframe.\n",
        "    This can be used in Jupyter notebooks by importing this module and calling the tokenize_tweets() function\n",
        "\n",
        "    Args:\n",
        "        df = data frame object to apply cleaning to\n",
        "\n",
        "    Returns:\n",
        "        pandas data frame with cleaned tokens\n",
        "    \"\"\"\n",
        "\n",
        "    df['tokens'] = df.tweet.apply(preprocess_tweet)\n",
        "    num_texts = len(netflix_df)\n",
        "    print('Complete. Number of Tweets that have been cleaned and tokenized : {}'.format(num_texts))\n",
        "    return netflix_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYca0yH8AQS6",
        "outputId": "9accd19b-dd3c-4b6a-dc17-95dbe84c39d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.10/dist-packages (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweet-preprocessor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJWE5JKcswbn",
        "outputId": "b9ed261e-541e-478d-82da-39c547d70bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: tweet-preprocessor\n",
            "Version: 0.6.0\n",
            "Summary: Elegant tweet preprocessing\n",
            "Home-page: https://github.com/s/preprocessor\n",
            "Author: Said √ñzcan\n",
            "Author-email: UNKNOWN\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "pip show tweet-preprocessor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLetRkWZvzKT"
      },
      "outputs": [],
      "source": [
        "from preprocessor.api import clean, tokenize, parse\n",
        "\n",
        "# Tokenize tweets\n",
        "def tokenize_tweets(netflix_df, text):\n",
        "    return [tokenize(tweet) for tweet in netflix_df[text]]\n",
        "\n",
        "# Clean tweets\n",
        "def clean_tweets(netflix_df, text):\n",
        "    return [clean(tweet) for tweet in netflix_df[text]]\n",
        "\n",
        "# Parse tweets\n",
        "def parse_tweets(netflix_df, text):\n",
        "    return [parse(tweet) for tweet in netflix_df[text]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3x0skYyzZ-N",
        "outputId": "44d50e0b-5fce-4b53-cd08-d4a8dc021170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "pip install contractions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QSnbNQlxarG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import contractions\n",
        "\n",
        "def clean_tweets(df, column_name):\n",
        "    # Remove URLs\n",
        "    df[column_name] = df[column_name].apply(lambda x: re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", str(x)))\n",
        "\n",
        "    # Expand contractions\n",
        "    df[column_name] = df[column_name].apply(lambda x: contractions.fix(x))\n",
        "\n",
        "    # Remove special characters and numbers\n",
        "    df[column_name] = df[column_name].apply(lambda x: re.sub(r\"[^a-zA-Z]+\", \" \", str(x)))\n",
        "\n",
        "    # Convert to lowercase\n",
        "    df[column_name] = df[column_name].str.lower()\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    df[column_name] = df[column_name].apply(lambda x: \" \".join(str(x).split()))\n",
        "\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "DOFhnJ-owybG",
        "outputId": "4d8334c6-c899-4be6-f2de-b8ffe49aa524"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-95be9281-114a-462b-8159-598eccc03579\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>text</th>\n",
              "      <th>query</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@alan_muso</td>\n",
              "      <td>2023-06-30 06:15:00+00:00</td>\n",
              "      <td>i should say i am no fan of streamers lying ab...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@AtlanticCouncil</td>\n",
              "      <td>2023-06-29 17:35:00+00:00</td>\n",
              "      <td>netflix s selection of adele jjames as queen c...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@realasitget314</td>\n",
              "      <td>2023-06-30 00:14:00+00:00</td>\n",
              "      <td>now why netflix put out a movie with tomhanks ...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@ACMideast</td>\n",
              "      <td>2023-06-29 17:05:00+00:00</td>\n",
              "      <td>a recent trailer of the netflix series queen c...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PeterTorres14</td>\n",
              "      <td>2023-06-28 20:52:00+00:00</td>\n",
              "      <td>netflix jadapsmith an old man told me cleopatr...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@hercules_sanson</td>\n",
              "      <td>2023-06-28 17:27:00+00:00</td>\n",
              "      <td>here is a great story for a biopic instead of ...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>@JimothyReinz</td>\n",
              "      <td>2023-06-28 00:04:00+00:00</td>\n",
              "      <td>cleopatra was black netflix said so</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>@ferdelvillar87</td>\n",
              "      <td>2023-06-27 22:58:00+00:00</td>\n",
              "      <td>you are the worst human being un the world and...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>@ConversationUS</td>\n",
              "      <td>2023-06-25 14:01:00+00:00</td>\n",
              "      <td>the new netflix doc series on cleopatra aims t...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>@wordily797979</td>\n",
              "      <td>2023-06-25 13:50:00+00:00</td>\n",
              "      <td>how do you feel about elizabeth taylor a white...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>@h8theantichrist</td>\n",
              "      <td>2023-06-25 06:39:00+00:00</td>\n",
              "      <td>cleopatra was not black you are taking a fat l...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>@Cleoyourlatina</td>\n",
              "      <td>2023-06-24 19:09:00+00:00</td>\n",
              "      <td>they going to hell for this</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>@shaneforbes</td>\n",
              "      <td>2023-06-24 18:00:00+00:00</td>\n",
              "      <td>twitter doing twitter things though there is a...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>@magesticheart</td>\n",
              "      <td>2023-06-24 14:12:00+00:00</td>\n",
              "      <td>get it through your thick heads dei is a poiso...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>@NachevKristiyan</td>\n",
              "      <td>2023-06-24 08:49:00+00:00</td>\n",
              "      <td>sorry but knowing this is from jada makes it r...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95be9281-114a-462b-8159-598eccc03579')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-815042e3-077d-4fa9-8191-d51b40c50576\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-815042e3-077d-4fa9-8191-d51b40c50576')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-815042e3-077d-4fa9-8191-d51b40c50576 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95be9281-114a-462b-8159-598eccc03579 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95be9281-114a-462b-8159-598eccc03579');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "            username                  timestamp  \\\n",
              "0         @alan_muso  2023-06-30 06:15:00+00:00   \n",
              "1   @AtlanticCouncil  2023-06-29 17:35:00+00:00   \n",
              "2    @realasitget314  2023-06-30 00:14:00+00:00   \n",
              "3         @ACMideast  2023-06-29 17:05:00+00:00   \n",
              "4     @PeterTorres14  2023-06-28 20:52:00+00:00   \n",
              "5   @hercules_sanson  2023-06-28 17:27:00+00:00   \n",
              "6      @JimothyReinz  2023-06-28 00:04:00+00:00   \n",
              "7    @ferdelvillar87  2023-06-27 22:58:00+00:00   \n",
              "8    @ConversationUS  2023-06-25 14:01:00+00:00   \n",
              "9     @wordily797979  2023-06-25 13:50:00+00:00   \n",
              "10  @h8theantichrist  2023-06-25 06:39:00+00:00   \n",
              "11   @Cleoyourlatina  2023-06-24 19:09:00+00:00   \n",
              "12      @shaneforbes  2023-06-24 18:00:00+00:00   \n",
              "13    @magesticheart  2023-06-24 14:12:00+00:00   \n",
              "14  @NachevKristiyan  2023-06-24 08:49:00+00:00   \n",
              "\n",
              "                                                 text  \\\n",
              "0   i should say i am no fan of streamers lying ab...   \n",
              "1   netflix s selection of adele jjames as queen c...   \n",
              "2   now why netflix put out a movie with tomhanks ...   \n",
              "3   a recent trailer of the netflix series queen c...   \n",
              "4   netflix jadapsmith an old man told me cleopatr...   \n",
              "5   here is a great story for a biopic instead of ...   \n",
              "6                 cleopatra was black netflix said so   \n",
              "7   you are the worst human being un the world and...   \n",
              "8   the new netflix doc series on cleopatra aims t...   \n",
              "9   how do you feel about elizabeth taylor a white...   \n",
              "10  cleopatra was not black you are taking a fat l...   \n",
              "11                        they going to hell for this   \n",
              "12  twitter doing twitter things though there is a...   \n",
              "13  get it through your thick heads dei is a poiso...   \n",
              "14  sorry but knowing this is from jada makes it r...   \n",
              "\n",
              "                                                query  \n",
              "0   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "1   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "2   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "3   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "4   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "5   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "6   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "7   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "8   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "9   Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "10  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "11  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "12  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "13  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  \n",
              "14  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "netflix1_df = clean_tweets(netflix_df, 'text')\n",
        "netflix1_df.head(15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "HGw8YOa-1K2I",
        "outputId": "4e1593ec-bc2e-4881-fb46-22278b955a35"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-6844aabd-68dd-4244-ada8-06ff8f6aae80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>text</th>\n",
              "      <th>query</th>\n",
              "      <th>timestamp_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@alan_muso</td>\n",
              "      <td>2023-06-30 06:15:00+00:00</td>\n",
              "      <td>i should say i am no fan of streamers lying ab...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>30-06-2023 06:15:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@AtlanticCouncil</td>\n",
              "      <td>2023-06-29 17:35:00+00:00</td>\n",
              "      <td>netflix s selection of adele jjames as queen c...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>29-06-2023 17:35:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@realasitget314</td>\n",
              "      <td>2023-06-30 00:14:00+00:00</td>\n",
              "      <td>now why netflix put out a movie with tomhanks ...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>30-06-2023 00:14:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@ACMideast</td>\n",
              "      <td>2023-06-29 17:05:00+00:00</td>\n",
              "      <td>a recent trailer of the netflix series queen c...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>29-06-2023 17:05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PeterTorres14</td>\n",
              "      <td>2023-06-28 20:52:00+00:00</td>\n",
              "      <td>netflix jadapsmith an old man told me cleopatr...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>28-06-2023 20:52:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6844aabd-68dd-4244-ada8-06ff8f6aae80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-8f90ebc7-2b67-4cc2-9d12-8928dc8704cf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f90ebc7-2b67-4cc2-9d12-8928dc8704cf')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-8f90ebc7-2b67-4cc2-9d12-8928dc8704cf button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6844aabd-68dd-4244-ada8-06ff8f6aae80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6844aabd-68dd-4244-ada8-06ff8f6aae80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           username                 timestamp  \\\n",
              "0        @alan_muso 2023-06-30 06:15:00+00:00   \n",
              "1  @AtlanticCouncil 2023-06-29 17:35:00+00:00   \n",
              "2   @realasitget314 2023-06-30 00:14:00+00:00   \n",
              "3        @ACMideast 2023-06-29 17:05:00+00:00   \n",
              "4    @PeterTorres14 2023-06-28 20:52:00+00:00   \n",
              "\n",
              "                                                text  \\\n",
              "0  i should say i am no fan of streamers lying ab...   \n",
              "1  netflix s selection of adele jjames as queen c...   \n",
              "2  now why netflix put out a movie with tomhanks ...   \n",
              "3  a recent trailer of the netflix series queen c...   \n",
              "4  netflix jadapsmith an old man told me cleopatr...   \n",
              "\n",
              "                                               query    timestamp_cleaned  \n",
              "0  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  30-06-2023 06:15:00  \n",
              "1  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  29-06-2023 17:35:00  \n",
              "2  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  30-06-2023 00:14:00  \n",
              "3  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  29-06-2023 17:05:00  \n",
              "4  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  28-06-2023 20:52:00  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "netflix1_df['timestamp'] = pd.to_datetime(netflix1_df['timestamp'])  # Convert to datetime type\n",
        "\n",
        "# Clean and format the timestamp column\n",
        "netflix1_df['timestamp_cleaned'] = netflix1_df['timestamp'].dt.strftime('%d-%m-%Y %H:%M:%S')\n",
        "\n",
        "# Display the updated DataFrame\n",
        "netflix1_df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "7u5jrtG22CZ_",
        "outputId": "632a609f-40cf-4eb1-fda2-8262406e1bb8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-735740a5-db2b-4e5f-bb2c-d6c3cedc2028\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>text</th>\n",
              "      <th>query</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@alan_muso</td>\n",
              "      <td>i should say i am no fan of streamers lying ab...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>30-06-2023 06:15:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@AtlanticCouncil</td>\n",
              "      <td>netflix s selection of adele jjames as queen c...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>29-06-2023 17:35:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@realasitget314</td>\n",
              "      <td>now why netflix put out a movie with tomhanks ...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>30-06-2023 00:14:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@ACMideast</td>\n",
              "      <td>a recent trailer of the netflix series queen c...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>29-06-2023 17:05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@PeterTorres14</td>\n",
              "      <td>netflix jadapsmith an old man told me cleopatr...</td>\n",
              "      <td>Netflix Cleopatra since:2022-01-01 lang:en @Ne...</td>\n",
              "      <td>28-06-2023 20:52:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-735740a5-db2b-4e5f-bb2c-d6c3cedc2028')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-bde5b948-0191-42db-938d-20fa12c010e2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bde5b948-0191-42db-938d-20fa12c010e2')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-bde5b948-0191-42db-938d-20fa12c010e2 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-735740a5-db2b-4e5f-bb2c-d6c3cedc2028 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-735740a5-db2b-4e5f-bb2c-d6c3cedc2028');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           username                                               text  \\\n",
              "0        @alan_muso  i should say i am no fan of streamers lying ab...   \n",
              "1  @AtlanticCouncil  netflix s selection of adele jjames as queen c...   \n",
              "2   @realasitget314  now why netflix put out a movie with tomhanks ...   \n",
              "3        @ACMideast  a recent trailer of the netflix series queen c...   \n",
              "4    @PeterTorres14  netflix jadapsmith an old man told me cleopatr...   \n",
              "\n",
              "                                               query            timestamp  \n",
              "0  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  30-06-2023 06:15:00  \n",
              "1  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  29-06-2023 17:35:00  \n",
              "2  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  30-06-2023 00:14:00  \n",
              "3  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  29-06-2023 17:05:00  \n",
              "4  Netflix Cleopatra since:2022-01-01 lang:en @Ne...  28-06-2023 20:52:00  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DataFrame is named 'netflix1_df' and the columns are named 'timestamp' and 'timestamp_cleaned'\n",
        "netflix1_df.drop(columns=['timestamp'], inplace=True)  # Drop the original timestamp column\n",
        "netflix1_df.rename(columns={'timestamp_cleaned': 'timestamp'}, inplace=True)  # Rename the cleaned column\n",
        "\n",
        "# Display the updated DataFrame\n",
        "netflix1_df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss60EaUn2cdn"
      },
      "outputs": [],
      "source": [
        "\n",
        "netflix1_df['timestamp'] = pd.to_datetime(netflix1_df['timestamp'], utc=True)  # Convert to datetime type with UTC timezone\n",
        "netflix1_df = netflix1_df.sort_values(by='timestamp', ascending=False)  # Sort by timestamp\n",
        "\n",
        "# Convert timestamps to the desired format\n",
        "netflix1_df['timestamp'] = netflix1_df['timestamp'].dt.strftime('%d-%m-%Y %H:%M:%S')\n",
        "\n",
        "# Set the desired date format explicitly\n",
        "pd.set_option('display.date_dayfirst', True)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "netflix1_df.head(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnTEKBVJ6LpL"
      },
      "outputs": [],
      "source": [
        "\n",
        "netflix1_df = netflix1_df.rename(columns={'text': 'tweets'})\n",
        "\n",
        "# Display the updated DataFrame\n",
        "netflix1_df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_f292A5ymkV",
        "outputId": "1f1978c4-f51f-454a-b384-f0df52f32038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of rows in the dataset is: 20599\n"
          ]
        }
      ],
      "source": [
        "num_rows = netflix1_df.shape[0]\n",
        "print(f\"The number of rows in the dataset is: {num_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdxTqAbU8Pg6"
      },
      "outputs": [],
      "source": [
        "netflix1_df.drop_duplicates(inplace=True, subset=\"tweets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwnU6y68z9dh",
        "outputId": "2e7dbdcb-1622-4dcb-8689-1f8c4d00a665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of rows in the dataset is: 20184\n"
          ]
        }
      ],
      "source": [
        "num_rows = netflix1_df.shape[0]\n",
        "print(f\"The number of rows in the dataset is: {num_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfl3ELht_2ei",
        "outputId": "b9d8b69d-94cd-4a60-eb3b-4b9d050ebca4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download the necessary NLTK resource\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bbqlN9yBx3j",
        "outputId": "221913db-aa2e-4617-bba3-441aaa70b4ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download the necessary NLTK resource\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqShkX3y_piJ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "netflix1_df['tokenized_tweets'] = netflix1_df ['tweets'].apply(lambda x: [token for token in tokenizer.tokenize(x) if token.lower() not in stop_words])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zf8ukDf2Zj-",
        "outputId": "024dce92-762d-408a-d1cb-3aefb5e55536"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of rows in the dataset is: 20184\n"
          ]
        }
      ],
      "source": [
        "num_rows = netflix1_df.shape[0]\n",
        "print(f\"The number of rows in the dataset is: {num_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhGA6AMO68yR"
      },
      "outputs": [],
      "source": [
        "# Save DataFrame to Excel\n",
        "netflix1_df.to_excel('netflix1_tweets.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcN3W85v7Db2"
      },
      "outputs": [],
      "source": [
        "# Save DataFrame to CSV\n",
        "netflix1_df.to_csv('netflix1_tweets.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVJFTwA2Fhld"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Assuming your DataFrame is named 'netflix1_df' and the tokenized tweets will be stored in a new column named 'tokenized_tweets'\n",
        "tokenizer = TweetTokenizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "netflix1_df['tokenized_tweets'] = netflix1_df['tweets'].apply(lambda x: ' '.join([token for token in tokenizer.tokenize(x) if token.lower() not in stop_words]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fsn9up6B3UC3",
        "outputId": "7c5748d9-96e9-4d27-8497-841e41f55ff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of rows in the dataset is: 20184\n"
          ]
        }
      ],
      "source": [
        "num_rows = netflix1_df.shape[0]\n",
        "print(f\"The number of rows in the dataset is: {num_rows}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlgUIzZ8FnOQ"
      },
      "outputs": [],
      "source": [
        "# Save DataFrame to Excel\n",
        "netflix1_df.to_excel('netflix_tweets_nocomma.xlsx', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtQDGtwVFwla"
      },
      "outputs": [],
      "source": [
        "# Save DataFrame to CSV\n",
        "netflix1_df.to_csv('netflix_tweets_nocomma.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq4umb7Y5XhF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "netflixcleaned_df = pd.read_csv(r'/content/netflix_tweets_nocomma.csv') #load data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgOPTj1j6rNQ"
      },
      "outputs": [],
      "source": [
        "# convert datetime to date and add year column\n",
        "netflixcleaned_df['timestamp'] = pd.to_datetime(netflixcleaned_df['timestamp'],\n",
        "                                   errors='coerce')\n",
        "netflixcleaned_df['year'] = netflixcleaned_df['timestamp'].dt.year\n",
        "netflixcleaned_df['timestamp'] = netflixcleaned_df['timestamp'].dt.date\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH7gaVWh8I7h"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the year and month from the 'timestamp' column\n",
        "netflixcleaned_df['year'] = pd.DatetimeIndex(netflixcleaned_df['timestamp']).year\n",
        "netflixcleaned_df['month'] = pd.DatetimeIndex(netflixcleaned_df['timestamp']).month\n",
        "\n",
        "# Filter the DataFrame for tweets in the first 6 months of 2023\n",
        "tweets_2023_h1 = netflixcleaned_df[(netflixcleaned_df['year'] == 2023) & (netflixcleaned_df['month'] <= 6)]\n",
        "\n",
        "# Count the number of tweets per month in the 2023\n",
        "monthly_tweet_counts = tweets_2023_h1.groupby(['year', 'month']).size().reset_index(name='tweet_count')\n",
        "\n",
        "# Create a line plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(monthly_tweet_counts['month'], monthly_tweet_counts['tweet_count'], marker='o', linestyle='-', color='skyblue', linewidth=2, markersize=8, markerfacecolor='white', markeredgecolor='skyblue')\n",
        "plt.fill_between(monthly_tweet_counts['month'], monthly_tweet_counts['tweet_count'], color='skyblue', alpha=0.2)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Number of Tweets')\n",
        "plt.title('Number of Tweets in the First 6 Months of 2023')\n",
        "plt.grid(True)\n",
        "plt.xticks(range(1, 7), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun'])  # Setting x-axis ticks and labels\n",
        "plt.ylim(0, max(monthly_tweet_counts['tweet_count']) * 1.1)  # Adjusting y-axis limits for better visualization\n",
        "\n",
        "# Save the plot as a JPEG file\n",
        "plt.savefig('tweets_2023_h1.jpg', dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "FrKsgNSx0MeE",
        "outputId": "2532c82b-727d-4e51-c1b1-1c762d277058"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           username                                             tweets  \\\n",
              "0      @abuaardvark  nobody tell the egyptian netflix s queen cleop...   \n",
              "1       @JerrellZod  clickbait i will say it again i do not have a ...   \n",
              "2    @Champion2DRob      but cleopatra is black jada pinket told me so   \n",
              "3         @rotterr1  oh so racist comment xd if cleopatra was black...   \n",
              "4  @TheTrueEvilNick  egyptian people looked then like they look now...   \n",
              "\n",
              "                                               query   timestamp  \\\n",
              "0  https://twitter.com/search?f=live&q=cleopatra%...  2023-06-30   \n",
              "1  https://twitter.com/search?f=live&q=cleopatra%...  2023-06-30   \n",
              "2  https://twitter.com/search?f=live&q=cleopatra%...  2023-06-30   \n",
              "3  https://twitter.com/search?f=live&q=cleopatra%...  2023-06-30   \n",
              "4  https://twitter.com/search?f=live&q=cleopatra%...  2023-06-30   \n",
              "\n",
              "                                    tokenized_tweets  year  \n",
              "0  [nobody, tell, egyptian, netflix, queen, cleop...  2023  \n",
              "1  [clickbait, say, problem, gal, cleopatra, love...  2023  \n",
              "2             [cleopatra, black, jada, pinket, told]  2023  \n",
              "3  [oh, racist, comment, xd, cleopatra, black, na...  2023  \n",
              "4  [egyptian, people, looked, like, look, middle,...  2023  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-8fbfef2a-82c3-4347-b147-b55cbbb884fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>username</th>\n",
              "      <th>tweets</th>\n",
              "      <th>query</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>tokenized_tweets</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@abuaardvark</td>\n",
              "      <td>nobody tell the egyptian netflix s queen cleop...</td>\n",
              "      <td>https://twitter.com/search?f=live&amp;q=cleopatra%...</td>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>[nobody, tell, egyptian, netflix, queen, cleop...</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@JerrellZod</td>\n",
              "      <td>clickbait i will say it again i do not have a ...</td>\n",
              "      <td>https://twitter.com/search?f=live&amp;q=cleopatra%...</td>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>[clickbait, say, problem, gal, cleopatra, love...</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Champion2DRob</td>\n",
              "      <td>but cleopatra is black jada pinket told me so</td>\n",
              "      <td>https://twitter.com/search?f=live&amp;q=cleopatra%...</td>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>[cleopatra, black, jada, pinket, told]</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@rotterr1</td>\n",
              "      <td>oh so racist comment xd if cleopatra was black...</td>\n",
              "      <td>https://twitter.com/search?f=live&amp;q=cleopatra%...</td>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>[oh, racist, comment, xd, cleopatra, black, na...</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@TheTrueEvilNick</td>\n",
              "      <td>egyptian people looked then like they look now...</td>\n",
              "      <td>https://twitter.com/search?f=live&amp;q=cleopatra%...</td>\n",
              "      <td>2023-06-30</td>\n",
              "      <td>[egyptian, people, looked, like, look, middle,...</td>\n",
              "      <td>2023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fbfef2a-82c3-4347-b147-b55cbbb884fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-a523ddc9-9a97-414c-9e04-fa52a6d9ccb2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a523ddc9-9a97-414c-9e04-fa52a6d9ccb2')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-a523ddc9-9a97-414c-9e04-fa52a6d9ccb2 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fbfef2a-82c3-4347-b147-b55cbbb884fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fbfef2a-82c3-4347-b147-b55cbbb884fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# %% [code]\n",
        "# convert string of tokens into tokens list\n",
        "import re\n",
        "netflixcleaned_df['tokenized_tweets'] = netflixcleaned_df.tokenized_tweets.apply(lambda x: re.split('\\s', x))\n",
        "netflixcleaned_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwmMeXbmDVf5"
      },
      "outputs": [],
      "source": [
        "import gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBs5kV4iDwRA"
      },
      "outputs": [],
      "source": [
        "import sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vywzF3mUD1DE"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_soKy_gDsN2",
        "outputId": "66dd08db-29fd-447b-b9b8-c38fe2a8510f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YIwkgCPETP-",
        "outputId": "e0434013-24cc-42ee-b7b7-347c419eaa14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPyM-TM\n",
            "  Downloading GPyM_TM-3.0.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: GPyM-TM\n",
            "Successfully installed GPyM-TM-3.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install GPyM-TM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ionBoYfQJ9kb",
        "outputId": "1b10ae91-cd47-41a3-ead4-182e94399061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/rwalk/gsdmm.git\n",
            "  Cloning https://github.com/rwalk/gsdmm.git to /tmp/pip-req-build-d9ipx7vr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rwalk/gsdmm.git /tmp/pip-req-build-d9ipx7vr\n",
            "  Resolved https://github.com/rwalk/gsdmm.git to commit 4ad1b6b6976743681ee4976b4573463d359214ee\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gsdmm==0.1) (1.22.4)\n",
            "Building wheels for collected packages: gsdmm\n",
            "  Building wheel for gsdmm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gsdmm: filename=gsdmm-0.1-py3-none-any.whl size=4585 sha256=4777efc4283ef2cd1f27f59aaafd72438e47ca5453d598f4adc626478d7f0933\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-95psd6al/wheels/da/d3/6e/a612d7cff0fcfb6470b8c113fc04931ecffb466ac19b9c5f3c\n",
            "Successfully built gsdmm\n",
            "Installing collected packages: gsdmm\n",
            "Successfully installed gsdmm-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/rwalk/gsdmm.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SYoTfYc3e5a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Flatten the 'tokens' column to create a list of all tokens in the DataFrame\n",
        "all_tokens = [token for tokens_list in netflixcleaned_df['tokenized_tweets'] for token in tokens_list]\n",
        "\n",
        "# Calculate the frequency distribution of each word in the tokenized tweets column\n",
        "word_freq = pd.Series(all_tokens).value_counts().reset_index()\n",
        "word_freq.columns = ['word', 'frequency']\n",
        "\n",
        "# Calculate the cumulative distribution\n",
        "word_freq['cumulative_distinct_words'] = word_freq['frequency'].cumsum()\n",
        "word_freq['distinct_tokens'] = word_freq.index + 1\n",
        "word_freq['corpus_percent'] = (word_freq['cumulative_distinct_words'] / len(all_tokens)) * 100\n",
        "word_freq['distinct_words_percent'] = (word_freq['distinct_tokens'] / len(set(all_tokens))) * 100\n",
        "\n",
        "# Calculate the percentage of distinct words and corpus covered by the most and least frequent words\n",
        "most_freq_word_data = word_freq.iloc[31]\n",
        "least_freq_word_data = word_freq.iloc[-1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2BpLQ7AeavM",
        "outputId": "0ce21eba-383e-493a-b151-b8daae6065db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Preprocess and tokenize the text in 'netflixcleaned_df'\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweets'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    from nltk import FreqDist\n",
        "\n",
        "    # Calculate the frequency distribution of words\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "\n",
        "result_df = dynamic_stop_word_analyzer(flattened_tokens)\n",
        "\n",
        "\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "ySnnZ8sw3pvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and tokenize the text in 'netflixcleaned_df'\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweets'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "\n",
        "    from nltk import FreqDist\n",
        "\n",
        "    # Calculate the frequency distribution of words\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "\n",
        "    filtered_tokens = [word for word in tokens if word in most_common_words]\n",
        "\n",
        "    return filtered_tokens\n",
        "\n",
        "percentile_to_keep = 75\n",
        "filtered_tokens = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "filtered_df = pd.DataFrame({'text': [\" \".join(filtered_tokens)]})\n",
        "\n"
      ],
      "metadata": {
        "id": "b4QV0TA35a6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and tokenize the text in 'filtered_df'\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "filtered_df['tokens'] = filtered_df['text'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "filtered_tokens = [word for sublist in filtered_df['tokens'] for word in sublist]\n",
        "\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Calculate the frequency distribution of words\n",
        "freq_dist_filtered = FreqDist(filtered_tokens)\n",
        "\n",
        "print(freq_dist_filtered.most_common(10))\n",
        "\n",
        "filtered_freq_df = pd.DataFrame(freq_dist_filtered.items(), columns=['Word', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
        "print(filtered_freq_df)\n"
      ],
      "metadata": {
        "id": "W2eqJR5H6BoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the top 20 most common words\n",
        "num_words_to_plot = 20\n",
        "top_words = filtered_freq_df.head(num_words_to_plot)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(top_words['Word'], top_words['Frequency'])\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.xlabel('Word')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Top 20 Most Common Words (75% Most Frequent)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5DBXr3Vz6J5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and tokenize the text in your 'netflixcleaned_df'\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweets'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "    # Implement the function to generate frequency distribution and other information.\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "\n",
        "percentile_to_keep = 75\n",
        "most_common_words = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "netflixcleaned_df['filtered_text'] = netflixcleaned_df['tokens'].apply(lambda tokens: \" \".join([word for word in tokens if word in most_common_words]))\n",
        "\n"
      ],
      "metadata": {
        "id": "uK2A9Qs_6z0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['filtered_text'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    from nltk import FreqDist\n",
        "\n",
        "    # Calculate the frequency distribution of words\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "result_df = dynamic_stop_word_analyzer(flattened_tokens)\n",
        "\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "cLfjk95Q6YgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and tokenize the text in 'netflixcleaned_df'\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['filtered_text'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "percentile_to_keep = 75\n",
        "most_common_words = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "netflixcleaned_df['filtered'] = netflixcleaned_df['tokens'].apply(lambda tokens: \" \".join([word for word in tokens if word in most_common_words]))\n",
        "\n"
      ],
      "metadata": {
        "id": "kKLqC_4N9XDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess and tokenize the text in your 'netflixcleaned_df'\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download the stopwords corpus\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['filtered'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "filterresult_df = dynamic_stop_word_analyzer(flattened_tokens)\n",
        "\n",
        "print(filterresult_df)\n"
      ],
      "metadata": {
        "id": "RPQxaTad-p_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['filtered'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "# Calculate the frequency distribution of words in the 'filtered_text' column\n",
        "freq_dist_filtered = FreqDist(flattened_tokens)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Up9WHQFPAQWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['filtered'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "percentile_to_keep = 75\n",
        "most_common_words = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "netflixcleaned_df['shorttext'] = netflixcleaned_df['tokens'].apply(lambda tokens: \" \".join([word for word in tokens if word in most_common_words]))\n"
      ],
      "metadata": {
        "id": "x4UfZ6DOAvTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download the stopwords corpus\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['shorttext'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "shortresult_df = dynamic_stop_word_analyzer(flattened_tokens)\n",
        "\n",
        "print(shortresult_df)"
      ],
      "metadata": {
        "id": "ne8lWN0MCOUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['shorttext'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "percentile_to_keep = 75\n",
        "most_common_words = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "netflixcleaned_df['tweety'] = netflixcleaned_df['tokens'].apply(lambda tokens: \" \".join([word for word in tokens if word in most_common_words]))\n"
      ],
      "metadata": {
        "id": "ipuPZyBRC34H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download the stopwords corpus\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "\n",
        "shortresult_df = dynamic_stop_word_analyzer(flattened_tokens)\n",
        "\n",
        "print(shortresult_df)"
      ],
      "metadata": {
        "id": "PnEHBoJvWSsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download the stopwords corpus\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "shortresult_df = dynamic_stop_word_analyzer(flattened_tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "Qb1FQEiPFAWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "percentile_to_keep = 75\n",
        "most_common_words = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "netflixcleaned_df['tweety2'] = netflixcleaned_df['tokens'].apply(lambda tokens: \" \".join([word for word in tokens if word in most_common_words]))\n",
        "\n"
      ],
      "metadata": {
        "id": "G48SQ35MGwgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download the stopwords corpus\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety2'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "shortresult_df = dynamic_stop_word_analyzer(flattened_tokens)\n",
        "\n",
        "print(shortresult_df)"
      ],
      "metadata": {
        "id": "fHDC8yO5Q6TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety2'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "percentile_to_keep = 75\n",
        "most_common_words = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "netflixcleaned_df['tweety3'] = netflixcleaned_df['tokens'].apply(lambda tokens: \" \".join([word for word in tokens if word in most_common_words]))\n"
      ],
      "metadata": {
        "id": "I3ogL5ihX1p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download the stopwords corpus\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety3'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "shortresult_df = dynamic_stop_word_analyzer(flattened_tokens)\n",
        "\n",
        "print(shortresult_df)"
      ],
      "metadata": {
        "id": "Tdh0vI13YJs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety3'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "percentile_to_keep = 75\n",
        "most_common_words = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "netflixcleaned_df['tweety4'] = netflixcleaned_df['tokens'].apply(lambda tokens: \" \".join([word for word in tokens if word in most_common_words]))\n",
        "\n"
      ],
      "metadata": {
        "id": "YeOidhnTfndp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download the stopwords corpus\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety4'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "shortresult_df = dynamic_stop_word_analyzer(flattened_tokens)\n"
      ],
      "metadata": {
        "id": "XeNwpPtOY2e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety4'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "percentile_to_keep = 75\n",
        "most_common_words = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "netflixcleaned_df['tweety5'] = netflixcleaned_df['tokens'].apply(lambda tokens: \" \".join([word for word in tokens if word in most_common_words]))\n",
        "\n"
      ],
      "metadata": {
        "id": "c_Mn_0ZfYl_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download the stopwords corpus if not already present\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety5'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "shortresult_df = dynamic_stop_word_analyzer(flattened_tokens)\n"
      ],
      "metadata": {
        "id": "7moOtgd3ZEfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety5'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens, percentile_to_keep):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    num_words_to_keep = int(total_distinct_words * percentile_to_keep / 100)\n",
        "\n",
        "    most_common_words = [word for word, _ in freq_dist.most_common(num_words_to_keep)]\n",
        "\n",
        "    return most_common_words\n",
        "\n",
        "percentile_to_keep = 90\n",
        "most_common_words = dynamic_stop_word_analyzer(flattened_tokens, percentile_to_keep)\n",
        "\n",
        "netflixcleaned_df['tweety6'] = netflixcleaned_df['tokens'].apply(lambda tokens: \" \".join([word for word in tokens if word in most_common_words]))\n",
        "\n"
      ],
      "metadata": {
        "id": "S77WJix5ZcQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "# Download the stopwords corpus if not already present\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety6'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Define the stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stop words from the tokens\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
        "\n",
        "# Flatten the list of lists to a list of words\n",
        "flattened_tokens = [word for sublist in netflixcleaned_df['tokens'] for word in sublist]\n",
        "\n",
        "def dynamic_stop_word_analyzer(tokens):\n",
        "\n",
        "    freq_dist = FreqDist(tokens)\n",
        "\n",
        "    # Compute total distinct words and total corpus size\n",
        "    total_distinct_words = len(freq_dist)\n",
        "    total_corpus_size = len(tokens)\n",
        "\n",
        "    # Create a DataFrame to store the statistics\n",
        "    statistics_df = pd.DataFrame(columns=['num_of_words', 'dist_words%', 'corpus%'])\n",
        "\n",
        "    # Define the percentiles for computing the statistics\n",
        "    percentiles = [75, 80, 85, 90, 95, 100]\n",
        "\n",
        "    for percentile in percentiles:\n",
        "        num_words = int(total_distinct_words * percentile / 100)\n",
        "        words_freq_list = freq_dist.most_common(num_words)\n",
        "        words_corpus_coverage = sum([count for _, count in words_freq_list]) / total_corpus_size\n",
        "        dist_words_coverage = num_words / total_distinct_words * 100\n",
        "\n",
        "        statistics_df = statistics_df.append({\n",
        "            'num_of_words': num_words,\n",
        "            'dist_words%': dist_words_coverage,\n",
        "            'corpus%': words_corpus_coverage * 100\n",
        "        }, ignore_index=True)\n",
        "\n",
        "    return statistics_df\n",
        "\n",
        "shortresult_df = dynamic_stop_word_analyzer(flattened_tokens)\n",
        "\n",
        "print(shortresult_df)"
      ],
      "metadata": {
        "id": "n17tjuliZtl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety6'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def filter_stopwords_and_single_letters(tokens):\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words and len(token) > 1]\n",
        "    return filtered_tokens\n",
        "\n",
        "netflixcleaned_df['filtered_tokens'] = netflixcleaned_df['tokens'].apply(filter_stopwords_and_single_letters)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v27wTCpwb_B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['tweety6'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def filter_tokens(tokens):\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words and len(token) > 1]\n",
        "    filtered_tokens = list(set(filtered_tokens))  # Convert to set and back to list to remove duplicates\n",
        "    return filtered_tokens\n",
        "\n",
        "netflixcleaned_df['filtered_tokens'] = netflixcleaned_df['tokens'].apply(filter_tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "dsRYSEC6cnqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "columns_to_delete = ['filtered_text', 'tokens', 'shorttext', 'filtered', 'filtered_text', 'tweety', 'tweety2', 'tweety3', 'tweety4', 'tweety5']\n",
        "netflixcleaned_df.drop(columns=columns_to_delete, inplace=True)\n",
        "\n",
        "new_netflixcleaned_df = netflixcleaned_df.drop(columns=columns_to_delete)\n"
      ],
      "metadata": {
        "id": "gjFKEFsOhO-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the display module from IPython\n",
        "from IPython.display import display\n",
        "\n",
        "# Set the maximum width for displaying columns\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n"
      ],
      "metadata": {
        "id": "aRtvLQ7wgubj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename the 'tweety8' column to 'filtered_tweets'\n",
        "netflixcleaned_df.rename(columns={'tweety6': 'filtered_tweets'}, inplace=True)"
      ],
      "metadata": {
        "id": "giTL6BwijUYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import FreqDist\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "netflixcleaned_df['tokens'] = netflixcleaned_df['filtered_tweets'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "custom_stopwords = set(['would', 'ahram', 'let', 'projectsegfau', 'invidious', 'lt', 'made', 'birth', 'cleopa', 'documentary', 'via', 'movie', 'queen', 'million', 'nearly', 'ha', 'oh', 'series', 'rt', 'user', 'even', 'com', 'kid', 'show', 'netflix', 'cl', 'also'])\n",
        "custom_stopwords = set(word.lower() for word in custom_stopwords)  # Convert to lowercase\n",
        "\n",
        "def filter_stopwords(tokens):\n",
        "    filtered_tokens2 = [token for token in tokens if token.lower() not in stopwords.words('english') and token.lower() not in custom_stopwords and len(token) > 1]\n",
        "    return filtered_tokens2\n",
        "\n",
        "netflixcleaned_df['filtered_tokens2'] = netflixcleaned_df['tokens'].apply(filter_stopwords)\n",
        "\n",
        "all_tokens = [word for sublist in netflixcleaned_df['filtered_tokens2'] for word in sublist]\n",
        "freq_dist = FreqDist(all_tokens)\n",
        "\n"
      ],
      "metadata": {
        "id": "FIQFEKiRFTqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def filter_tokens(tokens):\n",
        "    filtered_tokens = [token for token in tokens if\n",
        "                       token.lower() not in stopwords.words('english') and\n",
        "                       token.lower() not in custom_stopwords and\n",
        "                       len(token) > 1]  # Remove stopwords and single letters\n",
        "\n",
        "    # Remove duplicates\n",
        "    filtered_tokens = list(dict.fromkeys(filtered_tokens))\n",
        "\n",
        "    return filtered_tokens\n",
        "\n",
        "netflixcleaned_df['filtered_tokens2'] = netflixcleaned_df['tokens'].apply(filter_tokens)\n",
        "\n",
        "all_tokens = [word for sublist in netflixcleaned_df['filtered_tokens2'] for word in sublist]\n",
        "freq_dist = FreqDist(all_tokens)\n",
        "\n",
        "most_frequent_words = freq_dist.most_common(25)\n",
        "print(\"Most frequent words:\")\n",
        "print(most_frequent_words)\n",
        "\n",
        "least_frequent_words = freq_dist.most_common()[-25:][::-1]\n",
        "print(\"Least frequent words:\")\n",
        "print(least_frequent_words)\n",
        "\n"
      ],
      "metadata": {
        "id": "GJv1g3EPMbQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the 'tokens' column\n",
        "netflixcleaned_df.drop('tokens', axis=1, inplace=True)\n",
        "\n",
        "netflixcleaned_df.drop('filtered_tokens', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "etb1zLhWOdLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netflixcleaned_df.rename(columns={'filtered_tokens2': 'filtered_tokens'}, inplace=True)"
      ],
      "metadata": {
        "id": "w8UQ32dQO6Lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA4dJwoPKQm9"
      },
      "outputs": [],
      "source": [
        "from gsdmm import MovieGroupProcess\n",
        "mgp = MovieGroupProcess(K=7, alpha=0.1, beta=0.01, n_iters=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2ADA9XKOYkr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "\n",
        "file_path = 'dumps/trained_models/7clusters.model'\n",
        "\n",
        "# Create the directory\n",
        "os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
        "\n",
        "# Open the file in write mode and save the model using pickle\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(mgp, file)\n",
        "\n",
        "# Close the file\n",
        "file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErrqgmmzDJtg"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Train STTM model\n",
        "#    K = number of potential topics\n",
        "#    alpha = controls completeness\n",
        "#    beta =  controls homogeneity\n",
        "#    n_iters = number of iterations\n",
        "vocab = set(x for doc in docs for x in doc)\n",
        "n_terms = len(vocab)\n",
        "y = mgp.fit(docs, n_terms)\n",
        "\n",
        "# Save model\n",
        "with open('dumps/trained_models/7clusters.model', 'wb') as f:\n",
        "    pickle.dump(mgp, f)\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By0HCtPMO3U3"
      },
      "outputs": [],
      "source": [
        "# load in trained model\n",
        "filehandler = open('dumps/trained_models/7clusters.model', 'rb')\n",
        "mgp = pickle.load(filehandler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2c5DrD_O30-"
      },
      "outputs": [],
      "source": [
        "# define helper functions\n",
        "def top_words(cluster_word_distribution, top_cluster, values):\n",
        "    '''prints the top words in each cluster'''\n",
        "    for cluster in top_cluster:\n",
        "        sort_dicts =sorted(mgp.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
        "        print('Cluster %s : %s'%(cluster,sort_dicts))\n",
        "        print(' ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî')\n",
        "\n",
        "def cluster_importance(mgp):\n",
        "    '''returns a word-topic matrix[phi] where each value represents\n",
        "    the word importance for that particular cluster;\n",
        "    phi[i][w] would be the importance of word w in topic i.\n",
        "    '''\n",
        "    n_z_w = mgp.cluster_word_distribution\n",
        "    beta, V, K = mgp.beta, mgp.vocab_size, mgp.K\n",
        "    phi = [{} for i in range(K)]\n",
        "    for z in range(K):\n",
        "        for w in n_z_w[z]:\n",
        "            phi[z][w] = (n_z_w[z][w]+beta)/(sum(n_z_w[z].values())+V*beta)\n",
        "    return phi\n",
        "\n",
        "def topic_allocation(df, docs, mgp, topic_dict):\n",
        "    '''allocates all topics to each document in original dataframe,\n",
        "    adding two columns for cluster number and cluster description'''\n",
        "    topic_allocations = []\n",
        "    for doc in tqdm(docs):\n",
        "        topic_label, score = mgp.choose_best_label(doc)\n",
        "        topic_allocations.append(topic_label)\n",
        "\n",
        "    df['cluster'] = topic_allocations\n",
        "\n",
        "    df['topic_name'] = df.cluster.apply(lambda x: get_topic_name(x, topic_dict))\n",
        "    print('Complete. Number of documents with topic allocated: {}'.format(len(df)))\n",
        "\n",
        "def get_topic_name(doc, topic_dict):\n",
        "    '''returns the topic name string value from a dictionary of topics'''\n",
        "    topic_desc = topic_dict[doc]\n",
        "    return topic_desc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e1d-I2nPw4u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrLz7F6-PZAF"
      },
      "outputs": [],
      "source": [
        "doc_count = np.array(mgp.cluster_doc_count)\n",
        "print('Number of documents per topic :', doc_count)\n",
        "print('*'*20)\n",
        "\n",
        "# topics sorted by the number of documents they are allocated to\n",
        "top_index = doc_count.argsort()[-10:][::-1]\n",
        "print('Most important clusters (by number of docs inside):', top_index)\n",
        "print('*'*20)\n",
        "\n",
        "# show the top 7 words in term frequency for each cluster\n",
        "topic_indices = np.arange(start=0, stop=len(doc_count), step=1)\n",
        "top_words(mgp.cluster_word_distribution, topic_indices, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQjY81MQF-PA"
      },
      "outputs": [],
      "source": [
        "unwanted_words = ['projectsegfau', 'watch', 'documentary', 'play', 'lt', 'v', 'told', 'movie', 'said','invidious', 'com', 'x', 'series', 'let', 'would','netflix', 'via', 'alone', 'los', 'queen', 'youtube']\n",
        "\n",
        "def remove_unwanted_words(tokens):\n",
        "    return [token for token in tokens if token not in unwanted_words]\n",
        "\n",
        "# Apply the function to the tokenized_tweets column\n",
        "netflixcleaned_df['filtered_tokens'] = netflixcleaned_df['filtered_tokens'].apply(remove_unwanted_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMBL7MnuRe4B"
      },
      "outputs": [],
      "source": [
        "def top_words(cluster_word_distribution, top_cluster, values, unwanted_words):\n",
        "    '''prints the top words in each cluster, excluding unwanted words'''\n",
        "    for cluster in top_cluster:\n",
        "        sort_dicts = sorted(cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)\n",
        "        filtered_words = [(word, freq) for word, freq in sort_dicts if word not in unwanted_words][:values]\n",
        "        print('Cluster %s : %s' % (cluster, filtered_words))\n",
        "        print(' ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ov_Oj0TRcgF",
        "outputId": "61c2a0ed-1a54-4cd0-e6c8-f48c8723a382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster 0 : [('cleopatra', 1667), ('black', 858), ('egyptian', 531), ('egypt', 510), ('history', 268), ('controversy', 247), ('news', 213)]\n",
            " ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî\n",
            "Cluster 1 : [('black', 3758), ('cleopatra', 3622), ('white', 1213), ('people', 721), ('woman', 423), ('history', 321), ('greek', 291)]\n",
            " ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî\n",
            "Cluster 2 : [('cleopatra', 2083), ('black', 575), ('history', 448), ('audience', 289), ('woke', 250), ('score', 238), ('rotten', 187)]\n",
            " ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî\n",
            "Cluster 3 : [('cleopatra', 3760), ('black', 3735), ('greek', 1685), ('egypt', 1041), ('white', 912), ('people', 688), ('macedonian', 686)]\n",
            " ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî\n",
            "Cluster 4 : [('cleopatra', 676), ('black', 527), ('controversy', 105), ('history', 96), ('casting', 88), ('media', 74), ('fear', 68)]\n",
            " ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî\n",
            "Cluster 5 : [('cleopatra', 6847), ('black', 5780), ('history', 1672), ('people', 1234), ('greek', 1184), ('white', 1098), ('egyptian', 662)]\n",
            " ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî\n",
            "Cluster 6 : [('cleopatra', 3973), ('black', 2774), ('history', 543), ('greek', 482), ('people', 444), ('propaganda', 432), ('white', 422)]\n",
            " ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî\n"
          ]
        }
      ],
      "source": [
        "top_words(mgp.cluster_word_distribution, topic_indices, 7, unwanted_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ydo0e227dlj3"
      },
      "outputs": [],
      "source": [
        "phi = cluster_importance(mgp) # initialize phi matrix\n",
        "\n",
        "# 'woke' term importance for cluster 2 and 3\n",
        "print(phi[0]['woke'])\n",
        "print(phi[2]['woke'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHi_bbFtkuI4"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_0Nk0KiprMZ"
      },
      "outputs": [],
      "source": [
        "def topic_allocation(netflixcleaned_df, docs, mgp, topic_dict, unwanted_words):\n",
        "    '''\n",
        "    allocating topics back to original data frame\n",
        "    adding two columns for cluster number and cluster description\n",
        "    '''\n",
        "    topic_allocations = []\n",
        "    for doc in tqdm(docs):\n",
        "        topic_label, score = mgp.choose_best_label(doc)\n",
        "\n",
        "        # Filter out unwanted words from the topic\n",
        "        filtered_topic = [word for word in topic_label if word not in unwanted_words]\n",
        "\n",
        "        topic_allocations.append(filtered_topic)\n",
        "\n",
        "    df['topic_labels'] = topic_allocations\n",
        "    df['topic_description'] = df['topic_labels'].apply(lambda x: [topic_dict[topic] for topic in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY8Vu23kelbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8104e5e3-8dcf-44b1-9cc4-760656f6a281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20184/20184 [00:09<00:00, 2115.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete. Number of documents with topic allocated: 20184\n"
          ]
        }
      ],
      "source": [
        "# Define dictionary topics in the same sequential order\n",
        "# as resulting clusters from the gsdmm model\n",
        "topic_dict = {}\n",
        "topic_names = ['fit',\n",
        "               'inclusion',\n",
        "               'social context independency',\n",
        "               'realistic plot',\n",
        "               'conformity',\n",
        "               'historical value',\n",
        "               'motivation']\n",
        "\n",
        "for i, (topic_num, topic_name) in enumerate(zip(topic_indices, topic_names)):\n",
        "    topic_dict[topic_num] = topic_name\n",
        "\n",
        "topic_allocation(netflixcleaned_df, docs, mgp, topic_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ez-vjFlulOob",
        "outputId": "a56b21d5-8d9c-4986-e371-9fa3c0170976"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     tweets  \\\n",
              "2637                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   changes are fine as long as they do not try to rewrite history a black cleopatra give me a break lol   \n",
              "15512                                                                                                                                                                                                                                                                                                           how about if you have a bunch of black actors playing white people like in hamilton ignoramus a black woman playing cleopatra there is zero difference between any actor playing a different race or culture except for the whining babies who get their diapers in a twist   \n",
              "6289                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       queen cleopatra why are egyptians angry over the new netflix series usajaunnews com queen cleopa   \n",
              "8407                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                did not she technically colonize cleopatra for making an egyptian black   \n",
              "18710                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          queen cleopatra is not black   \n",
              "16926                                                                                                                                                                                                                                                                                                                                                                                       skin color of cleopatra controversy aside this looks listless and uninteresting netflix truly is declining queen cleopatra official trailer netflix invidious projectsegfau lt watch v ikthcpyn   \n",
              "19466                                                                                                                                                                                                                                                                                                                                                                                                                                                                            better this than changing history by making cleopatra black it is racist towards greek and egyptian people   \n",
              "14203                                                                                                                                                                                                                                                                                                                                                                                                                                                          there is a new cleopatra movie out interesting well this is what i am watching queen cleopatra documentary series on netflix   \n",
              "1928                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            my grammama says cleopatra was black energy   \n",
              "19960                                                                                                                                                                                                                                                                                                    cleopatra is unique given how she was the only greek ptolemy ruling egypt who even bothered to learn the native egyptian language octavian s propaganda painted her as a greedy lustful oriental sorceress who bewitched mark antony caesar just viewed her as a hellenistic ruler   \n",
              "12276                                                                                                                                                                                                                                                                                                                                                                                                          i would like to weigh in on the cleopatra debate she was neither black nor white but indian her ancestors came from orissa the patra suffix should have been a dead giveaway   \n",
              "7062                                                                                                                                                                                                                                                                                                                                                                                                                                wait egypt is mad plus cleopatra was macedonian greek not black now if they made a fantasy s show in stead of a documentary no one would care some much   \n",
              "2744                                                                                                                                                                                                                                                                                                                i hate what they did to cleopatra forcefully making every character black does not make sense one woman says in the documentary that her mother told her to believe cleopatra was black and asked her not to believe anybody who said differently such amazing research   \n",
              "8568                                                                                                                                                                                                                                                                                                                                come on thebabylonbee need a netflix pitch meeting sketch white males must be flawed naive stupid or murder culprits thediplomat glassonion minorities must be unflawed intelligent thediplomat glassonion enolaholmes historic figures black cleopatra   \n",
              "13970                                                                                                                                                                                                                                                                                                                                                                                                                                                        oh my i do not think i have seen so many negative reviews as i have for cleopatra on netflix now i am intrigued and must watch   \n",
              "11751                                                                                                                                                                                                                                                                                                                                                                                                                                             the historian that comments during the show made a comment that her grandma told her cleopatra was black it must be true she was egyptian   \n",
              "10352                                                                                                                                                                                                                                                                                                         that is what you get when you try revisionist history i had this on for minutes at some black woman tells everyone that her mother told her do not believe what you hear cleopatra was black that was their opening and closing statement for me zerohedge com political netf   \n",
              "18799                                                                                                                                                                                                                                                                                                                                                                                                                                                                   here are the average high annual temperatures for where i live and where cleopatra lived the sun does not bother us   \n",
              "18054                                                                                                                                                                                                                                                                                                           netflix jadapsmith no cleopatra s heritage is not highly debated it is well known that she was a macedonian woman the ptolemys are macedonian greek and known for incest she is a greek woman crack open a history book jada cleopatra netflix bbc com news world middle ea   \n",
              "4491   a sculpture depicting king tut as a black man is kicking up a storm in egypt following the kerfuffle over the black cleopatra in netflix s documentary the statue is featured in a dutch exhibition that pairs egyptian antiquities with works from black culture kemet egypt in hip hop jazz soul and funk pairs egyptian antiquities from the museum s collection with work inspired by ancient egyptian culture created by musicians of the african diaspora including miles davis erykah badu beyonc and rihanna david cortes i am hip hop national museum of antiquities leiden   \n",
              "\n",
              "               username   timestamp  \\\n",
              "2637   @JohnTho05838499  2023-01-06   \n",
              "15512     @GarryConner6  2023-07-05   \n",
              "6289           @UsaJaun  2023-05-19   \n",
              "8407          @ShotoLea  2023-05-18   \n",
              "18710       @HabibaEamd  2023-04-16   \n",
              "16926        @ranjoydey  2023-04-26   \n",
              "19466   @Dimitris_Soult  2023-04-13   \n",
              "14203         @italiacb  2023-11-05   \n",
              "1928     @SithisForever  2023-06-06   \n",
              "19960   @ArmaOrientalis  2020-08-07   \n",
              "12276     @ShawshankOne  2023-05-14   \n",
              "7062     @dragonanime10  2023-05-19   \n",
              "2744   @Mango__Republic  2023-05-31   \n",
              "8568      @plan4reality  2023-05-17   \n",
              "13970  @Kathy_Dominguez  2023-11-05   \n",
              "11751    @JasonPrisbrey  2023-05-15   \n",
              "10352      @LouisGbooks  2023-05-16   \n",
              "18799    @ElGrecoAnglos  2023-04-15   \n",
              "18054    @ApricotHearts  2023-04-20   \n",
              "4491            @cobbo3  2023-05-23   \n",
              "\n",
              "                                                                                                                                                                        filtered_tokens  \\\n",
              "2637                                                                                                            [fine, long, try, rewrite, history, black, cleopatra, give, break, lol]   \n",
              "15512                                         [bunch, black, actors, playing, white, hamilton, woman, cleopatra, zero, difference, actor, different, race, culture, except, get, twist]   \n",
              "6289                                                                                                                                                            [cleopatra, angry, new]   \n",
              "8407                                                                                                                                  [technically, cleopatra, making, egyptian, black]   \n",
              "18710                                                                                                                                                                [cleopatra, black]   \n",
              "16926                                                                                                     [skin, color, cleopatra, controversy, aside, looks, truly, official, trailer]   \n",
              "19466                                                                                           [better, changing, history, making, cleopatra, black, racist, towards, greek, egyptian]   \n",
              "14203                                                                                                                                     [new, cleopatra, interesting, well, watching]   \n",
              "1928                                                                                                                                                           [says, cleopatra, black]   \n",
              "19960           [cleopatra, given, greek, ptolemy, ruling, egypt, bothered, learn, native, egyptian, language, octavian, propaganda, painted, mark, antony, caesar, hellenistic, ruler]   \n",
              "12276                                                                                                         [cleopatra, debate, neither, black, white, indian, ancestors, came, dead]   \n",
              "7062                                                                                            [wait, egypt, mad, plus, cleopatra, macedonian, greek, black, fantasy, one, care, much]   \n",
              "2744                                              [hate, cleopatra, making, every, character, black, make, sense, one, woman, says, mother, believe, asked, anybody, amazing, research]   \n",
              "8568                                                                                                [come, need, white, must, stupid, intelligent, historic, figures, black, cleopatra]   \n",
              "13970                                                                                                                           [think, seen, many, negative, reviews, cleopatra, must]   \n",
              "11751                                                                                                   [historian, comments, comment, grandma, cleopatra, black, must, true, egyptian]   \n",
              "10352                                 [get, try, revisionist, history, minutes, black, woman, tells, everyone, mother, believe, hear, cleopatra, statement, zerohedge, political, netf]   \n",
              "18799                                                                                                                          [average, high, live, cleopatra, lived, sun, bother, us]   \n",
              "18054                                     [jadapsmith, cleopatra, heritage, highly, well, known, macedonian, woman, greek, incest, open, history, book, jada, bbc, news, world, middle]   \n",
              "4491   [depicting, king, tut, black, man, egypt, following, cleopatra, statue, egyptian, antiquities, works, culture, kemet, museum, work, ancient, created, african, including, miles]   \n",
              "\n",
              "       cluster                   topic_name  \n",
              "2637         5             historical value  \n",
              "15512        5             historical value  \n",
              "6289         0                          fit  \n",
              "8407         5             historical value  \n",
              "18710        5             historical value  \n",
              "16926        2  social context independency  \n",
              "19466        5             historical value  \n",
              "14203        5             historical value  \n",
              "1928         1                    inclusion  \n",
              "19960        6                   motivation  \n",
              "12276        5             historical value  \n",
              "7062         5             historical value  \n",
              "2744         5             historical value  \n",
              "8568         1                    inclusion  \n",
              "13970        6                   motivation  \n",
              "11751        5             historical value  \n",
              "10352        6                   motivation  \n",
              "18799        3               realistic plot  \n",
              "18054        3               realistic plot  \n",
              "4491         0                          fit  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-1d233413-d03f-432d-bf41-8fb692f29792\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>username</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>filtered_tokens</th>\n",
              "      <th>cluster</th>\n",
              "      <th>topic_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2637</th>\n",
              "      <td>changes are fine as long as they do not try to rewrite history a black cleopatra give me a break lol</td>\n",
              "      <td>@JohnTho05838499</td>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>[fine, long, try, rewrite, history, black, cleopatra, give, break, lol]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15512</th>\n",
              "      <td>how about if you have a bunch of black actors playing white people like in hamilton ignoramus a black woman playing cleopatra there is zero difference between any actor playing a different race or culture except for the whining babies who get their diapers in a twist</td>\n",
              "      <td>@GarryConner6</td>\n",
              "      <td>2023-07-05</td>\n",
              "      <td>[bunch, black, actors, playing, white, hamilton, woman, cleopatra, zero, difference, actor, different, race, culture, except, get, twist]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6289</th>\n",
              "      <td>queen cleopatra why are egyptians angry over the new netflix series usajaunnews com queen cleopa</td>\n",
              "      <td>@UsaJaun</td>\n",
              "      <td>2023-05-19</td>\n",
              "      <td>[cleopatra, angry, new]</td>\n",
              "      <td>0</td>\n",
              "      <td>fit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8407</th>\n",
              "      <td>did not she technically colonize cleopatra for making an egyptian black</td>\n",
              "      <td>@ShotoLea</td>\n",
              "      <td>2023-05-18</td>\n",
              "      <td>[technically, cleopatra, making, egyptian, black]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18710</th>\n",
              "      <td>queen cleopatra is not black</td>\n",
              "      <td>@HabibaEamd</td>\n",
              "      <td>2023-04-16</td>\n",
              "      <td>[cleopatra, black]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16926</th>\n",
              "      <td>skin color of cleopatra controversy aside this looks listless and uninteresting netflix truly is declining queen cleopatra official trailer netflix invidious projectsegfau lt watch v ikthcpyn</td>\n",
              "      <td>@ranjoydey</td>\n",
              "      <td>2023-04-26</td>\n",
              "      <td>[skin, color, cleopatra, controversy, aside, looks, truly, official, trailer]</td>\n",
              "      <td>2</td>\n",
              "      <td>social context independency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19466</th>\n",
              "      <td>better this than changing history by making cleopatra black it is racist towards greek and egyptian people</td>\n",
              "      <td>@Dimitris_Soult</td>\n",
              "      <td>2023-04-13</td>\n",
              "      <td>[better, changing, history, making, cleopatra, black, racist, towards, greek, egyptian]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14203</th>\n",
              "      <td>there is a new cleopatra movie out interesting well this is what i am watching queen cleopatra documentary series on netflix</td>\n",
              "      <td>@italiacb</td>\n",
              "      <td>2023-11-05</td>\n",
              "      <td>[new, cleopatra, interesting, well, watching]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1928</th>\n",
              "      <td>my grammama says cleopatra was black energy</td>\n",
              "      <td>@SithisForever</td>\n",
              "      <td>2023-06-06</td>\n",
              "      <td>[says, cleopatra, black]</td>\n",
              "      <td>1</td>\n",
              "      <td>inclusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19960</th>\n",
              "      <td>cleopatra is unique given how she was the only greek ptolemy ruling egypt who even bothered to learn the native egyptian language octavian s propaganda painted her as a greedy lustful oriental sorceress who bewitched mark antony caesar just viewed her as a hellenistic ruler</td>\n",
              "      <td>@ArmaOrientalis</td>\n",
              "      <td>2020-08-07</td>\n",
              "      <td>[cleopatra, given, greek, ptolemy, ruling, egypt, bothered, learn, native, egyptian, language, octavian, propaganda, painted, mark, antony, caesar, hellenistic, ruler]</td>\n",
              "      <td>6</td>\n",
              "      <td>motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12276</th>\n",
              "      <td>i would like to weigh in on the cleopatra debate she was neither black nor white but indian her ancestors came from orissa the patra suffix should have been a dead giveaway</td>\n",
              "      <td>@ShawshankOne</td>\n",
              "      <td>2023-05-14</td>\n",
              "      <td>[cleopatra, debate, neither, black, white, indian, ancestors, came, dead]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7062</th>\n",
              "      <td>wait egypt is mad plus cleopatra was macedonian greek not black now if they made a fantasy s show in stead of a documentary no one would care some much</td>\n",
              "      <td>@dragonanime10</td>\n",
              "      <td>2023-05-19</td>\n",
              "      <td>[wait, egypt, mad, plus, cleopatra, macedonian, greek, black, fantasy, one, care, much]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2744</th>\n",
              "      <td>i hate what they did to cleopatra forcefully making every character black does not make sense one woman says in the documentary that her mother told her to believe cleopatra was black and asked her not to believe anybody who said differently such amazing research</td>\n",
              "      <td>@Mango__Republic</td>\n",
              "      <td>2023-05-31</td>\n",
              "      <td>[hate, cleopatra, making, every, character, black, make, sense, one, woman, says, mother, believe, asked, anybody, amazing, research]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8568</th>\n",
              "      <td>come on thebabylonbee need a netflix pitch meeting sketch white males must be flawed naive stupid or murder culprits thediplomat glassonion minorities must be unflawed intelligent thediplomat glassonion enolaholmes historic figures black cleopatra</td>\n",
              "      <td>@plan4reality</td>\n",
              "      <td>2023-05-17</td>\n",
              "      <td>[come, need, white, must, stupid, intelligent, historic, figures, black, cleopatra]</td>\n",
              "      <td>1</td>\n",
              "      <td>inclusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13970</th>\n",
              "      <td>oh my i do not think i have seen so many negative reviews as i have for cleopatra on netflix now i am intrigued and must watch</td>\n",
              "      <td>@Kathy_Dominguez</td>\n",
              "      <td>2023-11-05</td>\n",
              "      <td>[think, seen, many, negative, reviews, cleopatra, must]</td>\n",
              "      <td>6</td>\n",
              "      <td>motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11751</th>\n",
              "      <td>the historian that comments during the show made a comment that her grandma told her cleopatra was black it must be true she was egyptian</td>\n",
              "      <td>@JasonPrisbrey</td>\n",
              "      <td>2023-05-15</td>\n",
              "      <td>[historian, comments, comment, grandma, cleopatra, black, must, true, egyptian]</td>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10352</th>\n",
              "      <td>that is what you get when you try revisionist history i had this on for minutes at some black woman tells everyone that her mother told her do not believe what you hear cleopatra was black that was their opening and closing statement for me zerohedge com political netf</td>\n",
              "      <td>@LouisGbooks</td>\n",
              "      <td>2023-05-16</td>\n",
              "      <td>[get, try, revisionist, history, minutes, black, woman, tells, everyone, mother, believe, hear, cleopatra, statement, zerohedge, political, netf]</td>\n",
              "      <td>6</td>\n",
              "      <td>motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18799</th>\n",
              "      <td>here are the average high annual temperatures for where i live and where cleopatra lived the sun does not bother us</td>\n",
              "      <td>@ElGrecoAnglos</td>\n",
              "      <td>2023-04-15</td>\n",
              "      <td>[average, high, live, cleopatra, lived, sun, bother, us]</td>\n",
              "      <td>3</td>\n",
              "      <td>realistic plot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18054</th>\n",
              "      <td>netflix jadapsmith no cleopatra s heritage is not highly debated it is well known that she was a macedonian woman the ptolemys are macedonian greek and known for incest she is a greek woman crack open a history book jada cleopatra netflix bbc com news world middle ea</td>\n",
              "      <td>@ApricotHearts</td>\n",
              "      <td>2023-04-20</td>\n",
              "      <td>[jadapsmith, cleopatra, heritage, highly, well, known, macedonian, woman, greek, incest, open, history, book, jada, bbc, news, world, middle]</td>\n",
              "      <td>3</td>\n",
              "      <td>realistic plot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4491</th>\n",
              "      <td>a sculpture depicting king tut as a black man is kicking up a storm in egypt following the kerfuffle over the black cleopatra in netflix s documentary the statue is featured in a dutch exhibition that pairs egyptian antiquities with works from black culture kemet egypt in hip hop jazz soul and funk pairs egyptian antiquities from the museum s collection with work inspired by ancient egyptian culture created by musicians of the african diaspora including miles davis erykah badu beyonc and rihanna david cortes i am hip hop national museum of antiquities leiden</td>\n",
              "      <td>@cobbo3</td>\n",
              "      <td>2023-05-23</td>\n",
              "      <td>[depicting, king, tut, black, man, egypt, following, cleopatra, statue, egyptian, antiquities, works, culture, kemet, museum, work, ancient, created, african, including, miles]</td>\n",
              "      <td>0</td>\n",
              "      <td>fit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d233413-d03f-432d-bf41-8fb692f29792')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-38a16e9e-dd7f-41d0-b454-d2218b3b78a7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38a16e9e-dd7f-41d0-b454-d2218b3b78a7')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-38a16e9e-dd7f-41d0-b454-d2218b3b78a7 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d233413-d03f-432d-bf41-8fb692f29792 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d233413-d03f-432d-bf41-8fb692f29792');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 253
        }
      ],
      "source": [
        "netflixcleaned_df[['tweets', 'username', 'timestamp', 'filtered_tokens', 'cluster', 'topic_name']].sample(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djG8ETuCEqHK"
      },
      "outputs": [],
      "source": [
        "def top_words_dict(cluster_word_distribution, top_cluster, n_words, unwanted_words):\n",
        "    '''returns a dictionary of the top n words and the number of docs they are in;\n",
        "    cluster numbers are the keys and a tuple of (word, word count) are the values'''\n",
        "    top_words_dict = {}\n",
        "    for cluster in top_cluster:\n",
        "        top_words_list = []\n",
        "        for val in range(0, n_words):\n",
        "            top_n_word = sorted(\n",
        "                [(word, count) for word, count in mgp.cluster_word_distribution[cluster].items() if word not in unwanted_words],\n",
        "                key=lambda item: item[1], reverse=True)[:n_words][val]\n",
        "            top_words_list.append(top_n_word)\n",
        "        top_words_dict[cluster] = top_words_list\n",
        "\n",
        "    return top_words_dict\n",
        "\n",
        "\n",
        "def get_word_counts_dict(top_words_nclusters, unwanted_words):\n",
        "    '''returns a dictionary that counts the number of times a word\n",
        "    appears only in the top n words list across all the clusters;\n",
        "    words are the keys and a count of the word is the value'''\n",
        "    word_count_dict = {}\n",
        "    for key in top_words_nclusters:\n",
        "        words_score_list = []\n",
        "        for word in top_words_nclusters[key]:\n",
        "            if word[0] not in unwanted_words:\n",
        "                if word[0] in word_count_dict.keys():\n",
        "                    word_count_dict[word[0]] += 1\n",
        "                else:\n",
        "                    word_count_dict[word[0]] = 1\n",
        "    return word_count_dict\n",
        "\n",
        "\n",
        "def get_cluster_importance_dict(top_words_nclusters, phi, unwanted_words):\n",
        "    '''returns a dictionary that of all top words and their cluster\n",
        "    importance value for each cluster;\n",
        "    cluster numbers are the keys and a list of word\n",
        "    importance computed scores are the values'''\n",
        "    cluster_importance_dict = {}\n",
        "    for key in top_words_nclusters:\n",
        "        words_score_list = []\n",
        "        for word in top_words_nclusters[key]:\n",
        "            if word[0] not in unwanted_words:\n",
        "                importance_score = phi[key][word[0]]\n",
        "                words_score_list.append(importance_score)\n",
        "        cluster_importance_dict[key] = words_score_list\n",
        "    return cluster_importance_dict\n",
        "\n",
        "\n",
        "def get_doc_counts_dict(top_words_nclusters, unwanted_words):\n",
        "    '''returns a dictionary of only the doc counts of each top n word for each cluster;\n",
        "    cluster numbers are the keys and a list of doc counts are the values'''\n",
        "    doc_counts_dict = {}\n",
        "    for key in top_words_nclusters:\n",
        "        doc_counts_list = []\n",
        "        for word in top_words_nclusters[key]:\n",
        "            if word[0] not in unwanted_words:\n",
        "                num_docs = word[1]\n",
        "                doc_counts_list.append(num_docs)\n",
        "        doc_counts_dict[key] = doc_counts_list\n",
        "    return doc_counts_dict\n",
        "\n",
        "\n",
        "def get_word_frequency_dict(top_words_nclusters, word_counts, unwanted_words):\n",
        "    '''returns a dictionary of only the number of occurrences across all\n",
        "    clusters for each word in a particular cluster's top n words;\n",
        "    cluster numbers are the keys and a list of\n",
        "    word occurrences counts are the values'''\n",
        "    word_frequency_dict = {}\n",
        "    for key in top_words_nclusters:\n",
        "        words_count_list = []\n",
        "        for word in top_words_nclusters[key]:\n",
        "            if word[0] not in unwanted_words:\n",
        "                words_count_list.append(word_counts[word[0]])\n",
        "        word_frequency_dict[key] = words_count_list\n",
        "\n",
        "    return word_frequency_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS0J0KFLWeBf"
      },
      "outputs": [],
      "source": [
        "def top_words_dict(cluster_word_distribution, top_cluster, n_words, unwanted_words):\n",
        "    '''returns a dictionary of the top n words and the number of docs they are in;\n",
        "    cluster numbers are the keys and a tuple of (word, word count) are the values'''\n",
        "\n",
        "    unwanted_set = set(unwanted_words)\n",
        "\n",
        "    top_words_dict = {}\n",
        "    for cluster in top_cluster:\n",
        "        top_words_list = []\n",
        "\n",
        "        filtered_cluster_word_dist = {word: count for word, count in cluster_word_distribution[cluster].items()\n",
        "                                      if word not in unwanted_set}\n",
        "\n",
        "\n",
        "        top_n_words = sorted(filtered_cluster_word_dist.items(), key=lambda item: item[1], reverse=True)[:n_words]\n",
        "\n",
        "        for word, count in top_n_words:\n",
        "            top_words_list.append((word, count))\n",
        "\n",
        "        top_words_dict[cluster] = top_words_list\n",
        "\n",
        "    return top_words_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1GAMmUinD9z"
      },
      "outputs": [],
      "source": [
        "# declare any static variables needed\n",
        "nwords = 10\n",
        "nclusters = len(topic_names)\n",
        "phi = cluster_importance(mgp)\n",
        "\n",
        "# define and generate dictionaries that hold each topic number and its values\n",
        "top_words = top_words_dict(mgp.cluster_word_distribution, topic_indices, nwords, unwanted_words)\n",
        "word_count = get_word_counts_dict(top_words, unwanted_words)\n",
        "word_frequency = get_word_frequency_dict(top_words, word_count, unwanted_words)\n",
        "cluster_importance_dict = get_cluster_importance_dict(top_words, phi, unwanted_words)\n",
        "\n",
        "\n",
        "# add all values for each topic to a list of lists\n",
        "rows_list = []\n",
        "for cluster in range(0, nclusters):\n",
        "    topic_name = topic_names[cluster]\n",
        "    words = [x[0] for x in top_words[cluster]]\n",
        "    doc_counts = [x[1] for x in top_words[cluster]]\n",
        "\n",
        "    # create a list of values which represents a 'row' in data frame\n",
        "    rows_list.append([int(cluster), topic_name, words, doc_counts,\n",
        "                      word_frequency[cluster], cluster_importance_dict[cluster]])\n",
        "\n",
        "topic_words_df = pd.DataFrame(data=rows_list,\n",
        "                              columns=['cluster', 'topic_name', 'top_words',\n",
        "                                       'doc_count', 'num_topic_occurrence', 'word_importance'])\n",
        "\n",
        "topic_words_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAWq1ivQtikx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "tweets_df = pd.read_csv(r'/content/sample_data/netflix7topics_results.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "L6JXM4vVuD64",
        "outputId": "e9e0764b-1944-4d99-ada9-7f7cd6592846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   cluster                   topic_name\n",
              "0        0                          fit\n",
              "1        1                    inclusion\n",
              "2        2  social context independency\n",
              "3        3               realistic plot\n",
              "4        4                   conformity\n",
              "5        5             historical value\n",
              "6        6                   motivation"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-3ca92d9c-c01f-4d3b-a175-a507abcbe779\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cluster</th>\n",
              "      <th>topic_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>fit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>inclusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>social context independency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>realistic plot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>conformity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>historical value</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ca92d9c-c01f-4d3b-a175-a507abcbe779')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-5b3bc030-60b9-4b22-bd57-9a0ef4891094\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b3bc030-60b9-4b22-bd57-9a0ef4891094')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-5b3bc030-60b9-4b22-bd57-9a0ef4891094 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ca92d9c-c01f-4d3b-a175-a507abcbe779 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ca92d9c-c01f-4d3b-a175-a507abcbe779');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 261
        }
      ],
      "source": [
        "# create data frame of unique cluster/topic names only\n",
        "topics_df = tweets_df[['cluster', 'topic_name']].drop_duplicates().sort_values(by='cluster')\n",
        "topics_df.reset_index(inplace=True, drop=True)\n",
        "topics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeTsos3Vul2l"
      },
      "outputs": [],
      "source": [
        "n_topics = len(topics_df)\n",
        "user_topic_counts = pd.pivot_table(data=tweets_df,\n",
        "                                   values='tweets',\n",
        "                                   index='year',\n",
        "                                   columns='cluster',\n",
        "                                   aggfunc='count',\n",
        "                                   fill_value=0)\n",
        "\n",
        "user_topic_counts.columns = ['Topic {}'.format(i) for i in range(n_topics)]\n",
        "user_topic_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qvh7a3ZJxoK9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "tweets_df['timestamp'] = pd.to_datetime(tweets_df['timestamp'])\n",
        "\n",
        "# Now extract the year and month from the timestamp column\n",
        "tweets_df['year'] = tweets_df['timestamp'].dt.year\n",
        "tweets_df['month'] = tweets_df['timestamp'].dt.month\n",
        "\n",
        "# Now filter the data for the first 6 months in 2023\n",
        "filtered_tweets_df = tweets_df[(tweets_df['year'] == 2023) & (tweets_df['month'] <= 6)]\n",
        "\n",
        "# Now create the pivot table and heatmap for the filtered data\n",
        "year_month_topic_counts = pd.pivot_table(data=filtered_tweets_df,\n",
        "                                        values='tweets',\n",
        "                                        index='month',\n",
        "                                        columns='cluster',\n",
        "                                        aggfunc='count',\n",
        "                                        fill_value=0)\n",
        "\n",
        "n_topics = len(year_month_topic_counts.columns)\n",
        "year_month_topic_counts.columns = ['Topic {}'.format(i) for i in range(n_topics)]\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(year_month_topic_counts, cmap='YlGnBu', annot=True, fmt='d', linewidths=0.5)\n",
        "plt.title('Tweet Counts by Topics for the First 6 Months of 2023')\n",
        "plt.xlabel('Topics')\n",
        "plt.ylabel('Months')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "tweets_df['timestamp'] = pd.to_datetime(tweets_df['timestamp'])\n",
        "\n",
        "# Now extract the year and month from the timestamp column\n",
        "tweets_df['year'] = tweets_df['timestamp'].dt.year\n",
        "tweets_df['month'] = tweets_df['timestamp'].dt.month\n",
        "\n",
        "# Now filter the data for the first 6 months in 2023\n",
        "filtered_tweets_df = tweets_df[(tweets_df['year'] == 2023) & (tweets_df['month'] <= 6)].copy()\n",
        "\n",
        "# Map the month numbers to the first 3 letters of the month names and set the order\n",
        "month_map = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr', 5: 'May', 6: 'Jun'}\n",
        "month_order = [month_map[i] for i in range(1, 7)]\n",
        "filtered_tweets_df['month'] = filtered_tweets_df['month'].map(month_map)\n",
        "filtered_tweets_df['month'] = pd.Categorical(filtered_tweets_df['month'], categories=month_order, ordered=True)\n",
        "\n",
        "# Map the topic numbers to the corresponding topic names using topic_dict\n",
        "topic_dict = {0: 'fit', 1: 'inclusion', 2: 'social context independency', 3: 'realistic plot',\n",
        "              4: 'conformity', 5: 'historical value', 6: 'motivation'}\n",
        "filtered_tweets_df['cluster'] = filtered_tweets_df['cluster'].map(topic_dict)\n",
        "\n",
        "# Now create the pivot table and heatmap for the filtered data\n",
        "year_month_topic_counts = pd.pivot_table(data=filtered_tweets_df,\n",
        "                                        values='tweets',\n",
        "                                        index='month',\n",
        "                                        columns='cluster',\n",
        "                                        aggfunc='count',\n",
        "                                        fill_value=0)\n",
        "\n",
        "# Sort the columns of the pivot table according to the order of the clusters\n",
        "year_month_topic_counts = year_month_topic_counts[topic_dict.values()]\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(14, 8))  # Adjust the figure size to accommodate longer x-axis labels\n",
        "sns.heatmap(year_month_topic_counts, cmap='YlGnBu', annot=True, fmt='d', linewidths=0.5)\n",
        "plt.title('Tweet Counts by Topics for the First 6 Months of 2023')\n",
        "plt.xlabel('Topics')\n",
        "plt.ylabel('Months')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8HYb36wxnOwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jukgpZMEzJgV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "topic_words_df = pd.read_pickle('/content/sample_data/netflix7topics_words.pkl')\n",
        "topic_words_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.scatter()\n",
        "\n",
        "# create a list to specify which topics to display first by default\n",
        "trace_default_visibilities = []\n",
        "\n",
        "for cluster in topic_words_df.cluster.values:\n",
        "    if cluster == 0:\n",
        "        trace_default_visibilities.append(True)\n",
        "    else:\n",
        "        trace_default_visibilities.append('legendonly')\n",
        "\n",
        "    # add each trace (set of scatter points for each cluster)\n",
        "    fig.add_scatter(x=topic_words_df.iloc[cluster].doc_count[0:10],  # Changed [0:5] to [0:10]\n",
        "                    y=topic_words_df.iloc[cluster].word_importance[0:10],  # Changed [0:5] to [0:10]\n",
        "                    mode='markers+text',\n",
        "                    opacity=0.6,\n",
        "                    marker=dict(size=topic_words_df.iloc[cluster].num_topic_occurrence[0:10],  # Changed [0:5] to [0:10]\n",
        "                                sizemode='area',\n",
        "                                sizeref=2. * max(topic_words_df.iloc[cluster].num_topic_occurrence[0:10]) / (40.** 2),\n",
        "                                sizemin=4\n",
        "                               ),\n",
        "                    hovertext=topic_words_df.iloc[cluster].top_words[0:10],  # Changed [0:5] to [0:10]\n",
        "                    hoverlabel=dict(font=dict(color='#FFFFFF')),\n",
        "                    text=topic_words_df.iloc[cluster].top_words[0:10],  # Changed [0:5] to [0:10]\n",
        "                    textposition='bottom center',\n",
        "                    visible=trace_default_visibilities[cluster],\n",
        "                    name=topic_words_df.iloc[cluster].topic_name\n",
        "                   )\n",
        "\n",
        "    fig.update_layout(\n",
        "        margin=dict(t=15,\n",
        "                    b=0,\n",
        "                    l=20,\n",
        "                    r=0),\n",
        "        xaxis=dict(title='Tweet Count'),\n",
        "        yaxis=dict(title='Word Importance'),\n",
        "        legend=dict(itemsizing='constant',\n",
        "                    title=dict(text='   <b>Topic</b>')),\n",
        "    )\n",
        "\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "bNgtKpe9pFK2",
        "outputId": "3d790b42-43a9-4e5b-e472-03ce4cc2fb53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"26fde359-01af-4947-b752-463ba022dbd8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"26fde359-01af-4947-b752-463ba022dbd8\")) {                    Plotly.newPlot(                        \"26fde359-01af-4947-b752-463ba022dbd8\",                        [{\"hovertemplate\":\"<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverlabel\":{\"font\":{\"color\":\"#FFFFFF\"}},\"hovertext\":[\"cleopatra\",\"black\",\"egyptian\",\"egypt\",\"history\",\"controversy\",\"news\",\"new\",\"docudrama\",\"woman\"],\"marker\":{\"size\":[7,7,5,5,6,2,1,1,1,3],\"sizemin\":4,\"sizemode\":\"area\",\"sizeref\":0.00875},\"mode\":\"markers+text\",\"name\":\"fit\",\"opacity\":0.6,\"text\":[\"cleopatra\",\"black\",\"egyptian\",\"egypt\",\"history\",\"controversy\",\"news\",\"new\",\"docudrama\",\"woman\"],\"textposition\":\"bottom center\",\"visible\":true,\"x\":[1667,858,531,510,268,247,213,196,158,153],\"y\":[0.06899327536884486,0.0355108368871348,0.02197714420046089,0.02110800797287633,0.011092247635949461,0.0102231114083649,0.008815938468466082,0.008112351998516674,0.006539629300982703,0.0063326921039387595],\"type\":\"scatter\"},{\"hoverlabel\":{\"font\":{\"color\":\"#FFFFFF\"}},\"hovertext\":[\"black\",\"cleopatra\",\"white\",\"people\",\"woman\",\"history\",\"greek\",\"make\",\"played\",\"mermaid\"],\"marker\":{\"size\":[7,7,4,4,3,6,4,1,1,1],\"sizemin\":4,\"sizemode\":\"area\",\"sizeref\":0.00875},\"mode\":\"markers+text\",\"name\":\"inclusion\",\"opacity\":0.6,\"text\":[\"black\",\"cleopatra\",\"white\",\"people\",\"woman\",\"history\",\"greek\",\"make\",\"played\",\"mermaid\"],\"textposition\":\"bottom center\",\"visible\":\"legendonly\",\"x\":[3758,3622,1213,721,423,321,291,269,250,248],\"y\":[0.06761087758613618,0.06516408277938619,0.021823430650998545,0.012971790614814767,0.007610431405906707,0.005775335300844216,0.005235601152296425,0.004839796110028044,0.004497964482614443,0.004461982206044591],\"type\":\"scatter\"},{\"hoverlabel\":{\"font\":{\"color\":\"#FFFFFF\"}},\"hovertext\":[\"cleopatra\",\"black\",\"history\",\"audience\",\"woke\",\"score\",\"rotten\",\"tv\",\"tomatoes\",\"jada\"],\"marker\":{\"size\":[7,7,6,1,1,1,1,1,1,1],\"sizemin\":4,\"sizemode\":\"area\",\"sizeref\":0.00875},\"mode\":\"markers+text\",\"name\":\"social context independency\",\"opacity\":0.6,\"text\":[\"cleopatra\",\"black\",\"history\",\"audience\",\"woke\",\"score\",\"rotten\",\"tv\",\"tomatoes\",\"jada\"],\"textposition\":\"bottom center\",\"visible\":\"legendonly\",\"x\":[2083,575,448,289,250,238,187,182,178,156],\"y\":[0.06818381193796907,0.018821980548557903,0.014664850186187068,0.009460253905738542,0.008183654818081356,0.007790855098802223,0.006121456291865904,0.005957789742166264,0.005826856502406553,0.005106723683728141],\"type\":\"scatter\"},{\"hoverlabel\":{\"font\":{\"color\":\"#FFFFFF\"}},\"hovertext\":[\"cleopatra\",\"black\",\"greek\",\"egypt\",\"white\",\"people\",\"macedonian\",\"egyptian\",\"african\",\"africa\"],\"marker\":{\"size\":[7,7,4,5,4,4,1,5,1,1],\"sizemin\":4,\"sizemode\":\"area\",\"sizeref\":0.00875},\"mode\":\"markers+text\",\"name\":\"realistic plot\",\"opacity\":0.6,\"text\":[\"cleopatra\",\"black\",\"greek\",\"egypt\",\"white\",\"people\",\"macedonian\",\"egyptian\",\"african\",\"africa\"],\"textposition\":\"bottom center\",\"visible\":\"legendonly\",\"x\":[3760,3735,1685,1041,912,688,686,663,545,492],\"y\":[0.06681739636045189,0.06637313293854309,0.029943532342021704,0.018499306593651087,0.01620690733660169,0.012226307076298867,0.012190766002546163,0.011782043654390069,0.009685120302980545,0.008743281848533895],\"type\":\"scatter\"},{\"hoverlabel\":{\"font\":{\"color\":\"#FFFFFF\"}},\"hovertext\":[\"cleopatra\",\"black\",\"controversy\",\"history\",\"casting\",\"media\",\"fear\",\"historical\",\"egyptian\",\"egypt\"],\"marker\":{\"size\":[7,7,2,6,1,1,1,2,5,5],\"sizemin\":4,\"sizemode\":\"area\",\"sizeref\":0.00875},\"mode\":\"markers+text\",\"name\":\"conformity\",\"opacity\":0.6,\"text\":[\"cleopatra\",\"black\",\"controversy\",\"history\",\"casting\",\"media\",\"fear\",\"historical\",\"egyptian\",\"egypt\"],\"textposition\":\"bottom center\",\"visible\":\"legendonly\",\"x\":[676,527,105,96,88,74,68,63,57,53],\"y\":[0.06594627604156506,0.05141099530578719,0.01024395859103378,0.009365988613704917,0.00858557085607926,0.00721983978023436,0.006634526462015117,0.006146765363499081,0.005561452045279838,0.005171243166467009],\"type\":\"scatter\"},{\"hoverlabel\":{\"font\":{\"color\":\"#FFFFFF\"}},\"hovertext\":[\"cleopatra\",\"black\",\"history\",\"people\",\"greek\",\"white\",\"egyptian\",\"historical\",\"egypt\",\"woman\"],\"marker\":{\"size\":[7,7,6,4,4,4,5,2,5,3],\"sizemin\":4,\"sizemode\":\"area\",\"sizeref\":0.00875},\"mode\":\"markers+text\",\"name\":\"historical value\",\"opacity\":0.6,\"text\":[\"cleopatra\",\"black\",\"history\",\"people\",\"greek\",\"white\",\"egyptian\",\"historical\",\"egypt\",\"woman\"],\"textposition\":\"bottom center\",\"visible\":\"legendonly\",\"x\":[6847,5780,1672,1234,1184,1098,662,559,553,549],\"y\":[0.07234342484071157,0.06106982741569843,0.017665949044607523,0.013038174281574949,0.012509889491274425,0.011601239651957527,0.006994596280536974,0.0059063296125178985,0.005842935437681836,0.005800672654457794],\"type\":\"scatter\"},{\"hoverlabel\":{\"font\":{\"color\":\"#FFFFFF\"}},\"hovertext\":[\"cleopatra\",\"black\",\"history\",\"greek\",\"people\",\"propaganda\",\"white\",\"egypt\",\"egyptian\",\"one\"],\"marker\":{\"size\":[7,7,6,4,4,1,4,5,5,1],\"sizemin\":4,\"sizemode\":\"area\",\"sizeref\":0.00875},\"mode\":\"markers+text\",\"name\":\"motivation\",\"opacity\":0.6,\"text\":[\"cleopatra\",\"black\",\"history\",\"greek\",\"people\",\"propaganda\",\"white\",\"egypt\",\"egyptian\",\"one\"],\"textposition\":\"bottom center\",\"visible\":\"legendonly\",\"x\":[3973,2774,543,482,444,432,422,394,318,294],\"y\":[0.06175990891951988,0.04312161432813845,0.008441017803224378,0.0074927809641299106,0.0069020760479727005,0.00671553765339674,0.006560088991250106,0.00612483273723953,0.004943422904925111,0.004570346115773189],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Tweet Count\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Word Importance\"}},\"legend\":{\"tracegroupgap\":0,\"title\":{\"text\":\"   <b>Topic</b>\"},\"itemsizing\":\"constant\"},\"margin\":{\"t\":15,\"b\":0,\"l\":20,\"r\":0}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('26fde359-01af-4947-b752-463ba022dbd8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2de3Rx-HpGdz",
        "outputId": "868515a2-87dd-474d-858b-55357c8ec66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "tweets_df['timestamp'] = pd.to_datetime(tweets_df['timestamp'])\n",
        "\n",
        "# Filter data for the year 2023 and months up to June (1 to 6)\n",
        "tweets_df_2023 = tweets_df[(tweets_df['timestamp'].dt.year == 2023) & (tweets_df['timestamp'].dt.month <= 6)]\n",
        "\n",
        "#Group data by clusters\n",
        "cluster_groups = tweets_df_2023.groupby('cluster')\n",
        "\n",
        "# Create a mapping dictionary for cluster numbers to cluster names\n",
        "cluster_name_map = dict(zip(topics_df['cluster'], topics_df['topic_name']))\n",
        "\n",
        "# Time Series Analysis and Step 6: Visualization\n",
        "for cluster, cluster_data in cluster_groups:\n",
        "    # Resample data to daily frequency and count the number of tweets per day\n",
        "    cluster_data_resampled = cluster_data.resample('D', on='timestamp').size()\n",
        "\n",
        "    # Calculate moving average for smoother trend visualization\n",
        "    moving_avg = cluster_data_resampled.rolling(window=7).mean()\n",
        "\n",
        "    # Plot time trends\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(cluster_data_resampled.index, cluster_data_resampled, label=cluster_name_map[cluster])\n",
        "    plt.plot(cluster_data_resampled.index, moving_avg, label=f'Moving Average ({cluster_name_map[cluster]})', color='red')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Number of Tweets')\n",
        "    plt.title(f'Time Trends for {cluster_name_map[cluster]} in 2023 (Up to June)')\n",
        "    plt.legend()\n",
        "\n",
        "    # Save the plot in the current working directory\n",
        "    file_name = f'time_trends_{cluster_name_map[cluster]}.png'\n",
        "    plt.savefig(file_name)\n",
        "\n",
        "    plt.close()  # Close the current figure to avoid overlapping of plots\n"
      ],
      "metadata": {
        "id": "m1uSKhWJqfDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_pickle('/content/netflix7topics_words (1).pkl')\n"
      ],
      "metadata": {
        "id": "NVdbO3miqlXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Calculate the total sum of values for each row and save it in a new column\n",
        "data['total_num_topic_occurrence'] = data['num_topic_occurrence'].apply(sum)\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "id": "JAuCDuYXEdkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "total_topics = 270\n",
        "\n",
        "# Calculate the HHI for each topic\n",
        "data['topic_hhi'] = (data['total_num_topic_occurrence'] / total_topics) ** 2\n",
        "\n",
        "# Calculate the overall HHI\n",
        "overall_hhi = data['topic_hhi'].sum()\n",
        "\n",
        "print(\"HHI for Each Topic:\")\n",
        "print(data['topic_hhi'])\n",
        "print(\"Overall HHI:\", overall_hhi)"
      ],
      "metadata": {
        "id": "U6s7gM2yH0nm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}